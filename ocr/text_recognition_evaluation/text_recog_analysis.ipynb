{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path_list = []\n",
    "gt_list = []\n",
    "pred_path_list = []\n",
    "pred_list = []\n",
    "pred_score_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_file = open('./log_results/gt.txt', 'r')\n",
    "for ground_truth in gt_file.readlines():\n",
    "    path, gt = ground_truth.rstrip().split()\n",
    "    gt_path_list.append(path)\n",
    "    gt_list.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file = open('./log_results/log_demo_result_case_sensitive.txt', 'r')\n",
    "for prediction in prediction_file.readlines():\n",
    "    path, pred, score = prediction.rstrip().split()\n",
    "    pred_path_list.append(path)\n",
    "    pred_list.append(pred)\n",
    "    pred_score_list.append(float(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_path_list) == len(pred_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.DataFrame({'path': gt_path_list, 'gt': gt_list})\n",
    "pred_df = pd.DataFrame({'path': pred_path_list, 'pred': pred_list, 'confidence_score': pred_score_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.merge(gt_df, pred_df, how='inner', on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 포함한 데이터 제외하기 위한 regex\n",
    "reg = re.compile(r'[a-zA-Z0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stats(df):\n",
    "    hangul_cnt = 0\n",
    "    correct_cnt = 0\n",
    "    wrong_cnt = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if not reg.match(row['gt']):\n",
    "            hangul_cnt += 1\n",
    "            continue\n",
    "        if row['gt'] == row['pred']:\n",
    "            correct_cnt += 1\n",
    "        else:\n",
    "            wrong_cnt += 1\n",
    "    tot_cnt = hangul_cnt + correct_cnt + wrong_cnt\n",
    "    score_w_hangul = correct_cnt/tot_cnt\n",
    "    score = correct_cnt/(correct_cnt+wrong_cnt)\n",
    "    return tot_cnt, hangul_cnt, correct_cnt, wrong_cnt, score_w_hangul, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter with confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_05 = concat_df[concat_df['confidence_score'] >= 0.5]\n",
    "filter_06 = concat_df[concat_df['confidence_score'] >= 0.6]\n",
    "filter_07 = concat_df[concat_df['confidence_score'] >= 0.7]\n",
    "filter_075 = concat_df[concat_df['confidence_score'] >= 0.75]\n",
    "filter_08 = concat_df[concat_df['confidence_score'] >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_stats(concat_df))\n",
    "print(count_stats(filter_05))\n",
    "print(count_stats(filter_06))\n",
    "print(count_stats(filter_07))\n",
    "print(count_stats(filter_075))\n",
    "print(count_stats(filter_08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_08[filter_08['gt'] != filter_08['pred']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccord_similarity(x, y):\n",
    "    numerator = len(set.intersection(*[set(x), set(y)]))\n",
    "    denominator = len(set.union(*[set(x), set(y)]))\n",
    "    return round((numerator/float(denominator)), 3)\n",
    "\n",
    "def custom_jaccord_similarity(x, y):\n",
    "    numerator = len(set.intersection(*[set(x), set(y)]))\n",
    "    denominator = len(set(y))\n",
    "    return round((numerator/float(denominator)), 3)\n",
    "\n",
    "test = \"test\"\n",
    "pred = \"pred\"\n",
    "print(jaccord_similarity(test, pred))\n",
    "print(custom_jaccord_similarity(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_jaccord(df):\n",
    "    hangul_cnt = 0\n",
    "    jaccord_correct = 0\n",
    "    jaccord_wrong = 0\n",
    "    custom_jaccord_correct = 0\n",
    "    custom_jaccord_wrong = 0\n",
    "    for row in df.iterrows():\n",
    "        jaccord = jaccord_similarity(row[1]['gt'], row[1]['pred'])\n",
    "        custom_jaccord = custom_jaccord_similarity(row[1]['gt'], row[1]['pred'])\n",
    "        if not reg.match(row[1]['gt']):\n",
    "            hangul_cnt += 1\n",
    "            continue\n",
    "        if jaccord >= 0.5:\n",
    "            jaccord_correct += 1\n",
    "        else:\n",
    "            jaccord_wrong += 1\n",
    "        if custom_jaccord >= 0.5:\n",
    "            custom_jaccord_correct += 1\n",
    "        else:\n",
    "            custom_jaccord_wrong += 1\n",
    "    return hangul_cnt, jaccord_correct, jaccord_wrong, jaccord_correct + jaccord_wrong, custom_jaccord_correct, custom_jaccord_wrong, custom_jaccord_correct + custom_jaccord_wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cal_jaccord(concat_df))\n",
    "print(cal_jaccord(filter_05))\n",
    "print(cal_jaccord(filter_06))\n",
    "print(cal_jaccord(filter_07))\n",
    "print(cal_jaccord(filter_075))\n",
    "print(cal_jaccord(filter_08))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Case-Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lower_list = []\n",
    "pred_lower_list = []\n",
    "pred_score_lower_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_file = open('./log_results/gt.txt', 'r')\n",
    "for ground_truth in gt_file.readlines():\n",
    "    _, gt = ground_truth.rstrip().split()\n",
    "    gt_lower_list.append(gt.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lower_file = open('./log_results/log_demo_result_no_case.txt', 'r')\n",
    "for prediction in prediction_lower_file.readlines():\n",
    "    _, pred, score = prediction.rstrip().split()\n",
    "    pred_lower_list.append(pred)\n",
    "    pred_score_lower_list.append(float(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_lower_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lower_df = pd.DataFrame({'path': gt_path_list, 'gt': gt_lower_list})\n",
    "pred_lower_df = pd.DataFrame({'path': pred_path_list, 'pred': pred_lower_list, 'confidence_score': pred_score_lower_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_concat_df = pd.merge(gt_lower_df, pred_lower_df, how='inner', on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_filter_05 = lower_concat_df[lower_concat_df['confidence_score'] >= 0.5]\n",
    "lower_filter_06 = lower_concat_df[lower_concat_df['confidence_score'] >= 0.6]\n",
    "lower_filter_07 = lower_concat_df[lower_concat_df['confidence_score'] >= 0.7]\n",
    "lower_filter_075 = lower_concat_df[lower_concat_df['confidence_score'] >= 0.75]\n",
    "lower_filter_08 = lower_concat_df[lower_concat_df['confidence_score'] >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_stats(lower_concat_df))\n",
    "print(count_stats(lower_filter_05))\n",
    "print(count_stats(lower_filter_06))\n",
    "print(count_stats(lower_filter_07))\n",
    "print(count_stats(lower_filter_075))\n",
    "print(count_stats(lower_filter_08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_filter_08[lower_filter_08['gt'] != lower_filter_08['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python ('text')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
