{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import timm\n",
    "import yaml\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, StepLR\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from easydict import EasyDict\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "num_epochs = 50\n",
    "accumulation_steps = 2\n",
    "batch_size = 64\n",
    "train_log_interval = 100\n",
    "\n",
    "LEARNING_RATE = 0.0001 \n",
    "lr_decay_step = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring csv & Delete noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'OpenData_PotOpenTabletIdntfc20220412.xls'\n",
    "df = pd.read_excel(filename, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete 구강정 데이터\n",
    "index_delete1 = df[df['품목일련번호']==200605327].index\n",
    "index_delete2 = df[df['품목일련번호']==200605328].index\n",
    "index_delete3 = df[df['품목일련번호']==200605329].index\n",
    "index_delete4 = df[df['품목일련번호']==200605330].index\n",
    "index_delete5 = df[df['품목일련번호']==200605331].index\n",
    "index_delete6 = df[df['품목일련번호']==200606263].index\n",
    "\n",
    "## delete 반원형 데이터\n",
    "index_delete7 = df[df['품목일련번호']==197800388].index\n",
    "index_delete8 = df[df['품목일련번호']==199906868].index\n",
    "index_delete9 = df[df['품목일련번호']==197900378].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index_delete1)\n",
    "df = df.drop(index_delete2)\n",
    "df = df.drop(index_delete3)\n",
    "df = df.drop(index_delete4)\n",
    "df = df.drop(index_delete5)\n",
    "df = df.drop(index_delete6)\n",
    "df = df.drop(index_delete7)\n",
    "df = df.drop(index_delete8)\n",
    "df = df.drop(index_delete9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_text_mark_nan = []\n",
    "for front, back in df.iloc[:, [6, 7]].values:\n",
    "    # nan: 0, text: 1, mark: 2\n",
    "    if type(front) is float and type(back) is float:\n",
    "        is_text_mark_nan.append(0)\n",
    "    else:\n",
    "        if (type(front) is not float and '마크' in front) or (type(back) is not float and '마크' in back):\n",
    "            is_text_mark_nan.append(2)\n",
    "        else:\n",
    "            is_text_mark_nan.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(29, 'text_mark_nan', is_text_mark_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(is_text_mark_nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index()\n",
    "        self.image_id = self.df['품목일련번호']\n",
    "        self.labels = self.df['text_mark_nan']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_id[idx]\n",
    "        label = self.labels[idx]\n",
    "        image_path = f'/opt/ml/data_handling/data/{image_id}.jpg'\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = df['품목일련번호']\n",
    "label = df['text_mark_nan']\n",
    "\n",
    "# https://teddylee777.github.io/scikit-learn/train-test-split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(image_num, label, test_size=0.2, stratify=label, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://mizykk.tistory.com/131\n",
    "\n",
    "train_zip = zip(x_train, y_train)\n",
    "train_df = pd.DataFrame(train_zip)\n",
    "train_df.columns = ['품목일련번호','text_mark_nan']\n",
    "\n",
    "val_zip = zip(x_valid, y_valid)\n",
    "val_df = pd.DataFrame(val_zip)\n",
    "val_df.columns = ['품목일련번호','text_mark_nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>품목일련번호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_mark_nan</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               품목일련번호\n",
       "text_mark_nan        \n",
       "0                 147\n",
       "1               16779\n",
       "2                2564"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('text_mark_nan').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "품목일련번호    19490\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('text_mark_nan').count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>품목일련번호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_mark_nan</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               품목일련번호\n",
       "text_mark_nan        \n",
       "0                  37\n",
       "1                4195\n",
       "2                 641"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.groupby('text_mark_nan').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "품목일련번호    4873\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.groupby('text_mark_nan').count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "val_dataset = CustomDataset(val_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          ...,\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529]],\n",
       " \n",
       "         [[1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          ...,\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707]],\n",
       " \n",
       "         [[2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          ...,\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(train_dataset))\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          ...,\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529]],\n",
       " \n",
       "         [[1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          ...,\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707]],\n",
       " \n",
       "         [[2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          ...,\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(val_dataset))\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'fbnetc_100',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_s16_224',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mnasnet_100',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_resnet50',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet101d',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_100',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b1-533bc792.pth\" to /opt/ml/.cache/torch/hub/checkpoints/efficientnet_b1-533bc792.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SiLU(inplace=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
       "        (bn2): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SiLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'efficientnet_b1'\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseoulsky_field\u001b[0m (\u001b[33mmedic\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/ml/final-project-level3-cv-16/wandb/run-20220526_011835-34nf052s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/medic/final-project/runs/34nf052s\" target=\"_blank\">KM_efficientnet_b1_text_mark_nan</a></strong> to <a href=\"https://wandb.ai/medic/final-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1420cd1d03354d63927d76a867e5898d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/50](100/305) || training loss 1.084 || training accuracy 77.86% || lr [0.0001]\n",
      "Epoch[0/50](200/305) || training loss 0.708 || training accuracy 80.11% || lr [0.0001]\n",
      "Epoch[0/50](300/305) || training loss 0.5774 || training accuracy 81.92% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.59459459 0.95899881 0.09360374]\n",
      "[Val] acc : 84.24%, loss: 0.53 || best acc : 84.24%, best loss: 0.53\n",
      "nan: 0.5945945945945946\n",
      "text: 0.9589988081048868\n",
      "mark: 0.093603744149766\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306b0ecaf9d144488e3712c12ec0de21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/50](100/305) || training loss 0.37 || training accuracy 86.50% || lr [0.0001]\n",
      "Epoch[1/50](200/305) || training loss 0.358 || training accuracy 86.47% || lr [0.0001]\n",
      "Epoch[1/50](300/305) || training loss 0.3697 || training accuracy 86.41% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.64864865 0.96066746 0.11544462]\n",
      "[Val] acc : 84.71%, loss: 0.52 || best acc : 84.71%, best loss: 0.52\n",
      "nan: 0.6486486486486487\n",
      "text: 0.9606674612634089\n",
      "mark: 0.11544461778471139\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99d6dd634af4917a576d052af5e15ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/50](100/305) || training loss 0.2696 || training accuracy 89.47% || lr [0.0001]\n",
      "Epoch[2/50](200/305) || training loss 0.2557 || training accuracy 90.39% || lr [0.0001]\n",
      "Epoch[2/50](300/305) || training loss 0.2741 || training accuracy 89.39% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.64864865 0.94851013 0.2199688 ]\n",
      "[Val] acc : 85.04%, loss: 0.45 || best acc : 85.04%, best loss: 0.45\n",
      "nan: 0.6486486486486487\n",
      "text: 0.9485101311084625\n",
      "mark: 0.21996879875195008\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c46d800114147cfab9188b2e20380ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/50](100/305) || training loss 0.173 || training accuracy 93.52% || lr [0.0001]\n",
      "Epoch[3/50](200/305) || training loss 0.1902 || training accuracy 92.75% || lr [0.0001]\n",
      "Epoch[3/50](300/305) || training loss 0.2149 || training accuracy 91.44% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.67567568 0.94779499 0.2324493 ]\n",
      "[Val] acc : 85.16%, loss: 0.48 || best acc : 85.16%, best loss: 0.45\n",
      "nan: 0.6756756756756757\n",
      "text: 0.9477949940405245\n",
      "mark: 0.23244929797191888\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62da0f9be99446c2bb9d7593ebd1d306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/50](100/305) || training loss 0.1258 || training accuracy 95.30% || lr [0.0001]\n",
      "Epoch[4/50](200/305) || training loss 0.1487 || training accuracy 94.20% || lr [0.0001]\n",
      "Epoch[4/50](300/305) || training loss 0.1585 || training accuracy 93.69% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.7027027  0.95280095 0.23712949]\n",
      "[Val] acc : 85.68%, loss: 0.51 || best acc : 85.68%, best loss: 0.45\n",
      "nan: 0.7027027027027027\n",
      "text: 0.9528009535160906\n",
      "mark: 0.23712948517940718\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e7e1d6928a4b0bbb935613b23753b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/50](100/305) || training loss 0.08853 || training accuracy 96.89% || lr [5e-05]\n",
      "Epoch[5/50](200/305) || training loss 0.07884 || training accuracy 97.17% || lr [5e-05]\n",
      "Epoch[5/50](300/305) || training loss 0.08227 || training accuracy 97.22% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.7027027  0.93134684 0.29797192]\n",
      "[Val] acc : 84.63%, loss:  0.5 || best acc : 85.68%, best loss: 0.45\n",
      "nan: 0.7027027027027027\n",
      "text: 0.93134684147795\n",
      "mark: 0.29797191887675506\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17204e97f4a24ab1b4052e21b1852b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/50](100/305) || training loss 0.05786 || training accuracy 98.16% || lr [5e-05]\n",
      "Epoch[6/50](200/305) || training loss 0.05788 || training accuracy 98.14% || lr [5e-05]\n",
      "Epoch[6/50](300/305) || training loss 0.05632 || training accuracy 98.36% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.7027027  0.94445769 0.29485179]\n",
      "[Val] acc : 85.72%, loss: 0.52 || best acc : 85.72%, best loss: 0.45\n",
      "nan: 0.7027027027027027\n",
      "text: 0.9444576877234804\n",
      "mark: 0.2948517940717629\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed03493440f4a80a937ba40ceb07498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/50](100/305) || training loss 0.0442 || training accuracy 98.73% || lr [5e-05]\n",
      "Epoch[7/50](200/305) || training loss 0.04411 || training accuracy 98.86% || lr [5e-05]\n",
      "Epoch[7/50](300/305) || training loss 0.0476 || training accuracy 98.55% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.72972973 0.9523242  0.26365055]\n",
      "[Val] acc : 86.00%, loss: 0.54 || best acc : 86.00%, best loss: 0.45\n",
      "nan: 0.7297297297297297\n",
      "text: 0.9523241954707986\n",
      "mark: 0.26365054602184085\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa5529f55a440a5abdc908026c8d598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/50](100/305) || training loss 0.03452 || training accuracy 99.02% || lr [5e-05]\n",
      "Epoch[8/50](200/305) || training loss 0.0387 || training accuracy 98.98% || lr [5e-05]\n",
      "Epoch[8/50](300/305) || training loss 0.03851 || training accuracy 98.95% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.72972973 0.93516091 0.30109204]\n",
      "[Val] acc : 85.02%, loss: 0.57 || best acc : 86.00%, best loss: 0.45\n",
      "nan: 0.7297297297297297\n",
      "text: 0.9351609058402861\n",
      "mark: 0.30109204368174725\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9904943da0174b7392cf2de0a5af290b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/50](100/305) || training loss 0.02684 || training accuracy 99.34% || lr [5e-05]\n",
      "Epoch[9/50](200/305) || training loss 0.0301 || training accuracy 99.25% || lr [5e-05]\n",
      "Epoch[9/50](300/305) || training loss 0.03038 || training accuracy 99.16% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95089392 0.25585023]\n",
      "[Val] acc : 85.80%, loss: 0.58 || best acc : 86.00%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9508939213349226\n",
      "mark: 0.25585023400936036\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c634d6a7f298471d9959245f41614336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/50](100/305) || training loss 0.02506 || training accuracy 99.44% || lr [2.5e-05]\n",
      "Epoch[10/50](200/305) || training loss 0.02087 || training accuracy 99.59% || lr [2.5e-05]\n",
      "Epoch[10/50](300/305) || training loss 0.02503 || training accuracy 99.52% || lr [2.5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.7027027  0.95637664 0.27145086]\n",
      "[Val] acc : 86.44%, loss: 0.58 || best acc : 86.44%, best loss: 0.45\n",
      "nan: 0.7027027027027027\n",
      "text: 0.9563766388557807\n",
      "mark: 0.2714508580343214\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad527753218a42acae485d5c10573509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/50](100/305) || training loss 0.01984 || training accuracy 99.50% || lr [2.5e-05]\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.72972973 0.95518474 0.28705148]\n",
      "[Val] acc : 86.56%, loss: 0.61 || best acc : 86.56%, best loss: 0.45\n",
      "nan: 0.7297297297297297\n",
      "text: 0.9551847437425507\n",
      "mark: 0.2870514820592824\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf2af7481974dbd80d9b3f81be6a9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19/50](100/305) || training loss 0.007408 || training accuracy 99.89% || lr [1.25e-05]\n",
      "Epoch[19/50](200/305) || training loss 0.009043 || training accuracy 99.91% || lr [1.25e-05]\n",
      "Epoch[19/50](300/305) || training loss 0.00773 || training accuracy 99.92% || lr [1.25e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.75675676 0.95852205 0.28237129]\n",
      "[Val] acc : 86.80%, loss: 0.61 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9585220500595948\n",
      "mark: 0.2823712948517941\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddd0873b3fc4d31b6ac7ea6e59cbbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/50](100/305) || training loss 0.007899 || training accuracy 99.88% || lr [6.25e-06]\n",
      "Epoch[20/50](200/305) || training loss 0.007843 || training accuracy 99.86% || lr [6.25e-06]\n",
      "Epoch[20/50](300/305) || training loss 0.007905 || training accuracy 99.88% || lr [6.25e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95446961 0.28393136]\n",
      "[Val] acc : 86.48%, loss: 0.61 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9544696066746127\n",
      "mark: 0.2839313572542902\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c972b4bb3e4743e7a183e877c057aa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21/50](100/305) || training loss 0.007577 || training accuracy 99.91% || lr [6.25e-06]\n",
      "Epoch[21/50](200/305) || training loss 0.007965 || training accuracy 99.89% || lr [6.25e-06]\n",
      "Epoch[21/50](300/305) || training loss 0.007437 || training accuracy 99.88% || lr [6.25e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95637664 0.28393136]\n",
      "[Val] acc : 86.64%, loss: 0.62 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9563766388557807\n",
      "mark: 0.2839313572542902\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2424f40cab1342e0abc9eccf6707ed2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22/50](200/305) || training loss 0.007005 || training accuracy 99.95% || lr [6.25e-06]\n",
      "Epoch[22/50](300/305) || training loss 0.007381 || training accuracy 99.84% || lr [6.25e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95733015 0.28081123]\n",
      "[Val] acc : 86.68%, loss: 0.62 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9573301549463648\n",
      "mark: 0.28081123244929795\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e248722f725430ea727ffca857c68b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23/50](200/305) || training loss 0.0062 || training accuracy 99.95% || lr [6.25e-06]\n",
      "Epoch[23/50](300/305) || training loss 0.00789 || training accuracy 99.86% || lr [6.25e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95733015 0.28393136]\n",
      "[Val] acc : 86.72%, loss: 0.62 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9573301549463648\n",
      "mark: 0.2839313572542902\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd6b10479db4b669e78f91193ee9e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24/50](100/305) || training loss 0.006305 || training accuracy 99.95% || lr [6.25e-06]\n",
      "Epoch[24/50](200/305) || training loss 0.006683 || training accuracy 99.91% || lr [6.25e-06]\n",
      "Epoch[24/50](300/305) || training loss 0.007029 || training accuracy 99.91% || lr [6.25e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.72972973 0.95876043 0.27925117]\n",
      "[Val] acc : 86.76%, loss: 0.62 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7297297297297297\n",
      "text: 0.9587604290822408\n",
      "mark: 0.2792511700468019\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52de652f93b4a8b81d178130bcd0da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25/50](100/305) || training loss 0.006086 || training accuracy 99.95% || lr [3.125e-06]\n",
      "Epoch[25/50](200/305) || training loss 0.00656 || training accuracy 99.95% || lr [3.125e-06]\n",
      "Epoch[25/50](300/305) || training loss 0.005872 || training accuracy 99.94% || lr [3.125e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95256257 0.29641186]\n",
      "[Val] acc : 86.48%, loss: 0.62 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9525625744934446\n",
      "mark: 0.296411856474259\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5557d8f4d6134c96ab7d039664460ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26/50](100/305) || training loss 0.005238 || training accuracy 99.97% || lr [3.125e-06]\n",
      "Epoch[26/50](200/305) || training loss 0.006389 || training accuracy 99.89% || lr [3.125e-06]\n",
      "Epoch[27/50](100/305) || training loss 0.005504 || training accuracy 99.94% || lr [3.125e-06]\n",
      "Epoch[27/50](200/305) || training loss 0.006341 || training accuracy 99.92% || lr [3.125e-06]\n",
      "Epoch[27/50](300/305) || training loss 0.005899 || training accuracy 99.97% || lr [3.125e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95065554 0.30733229]\n",
      "[Val] acc : 86.46%, loss: 0.61 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9506555423122766\n",
      "mark: 0.3073322932917317\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e811c89a1c3a4c778f4d479973b88e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28/50](100/305) || training loss 0.006756 || training accuracy 99.91% || lr [3.125e-06]\n",
      "Epoch[28/50](200/305) || training loss 0.006814 || training accuracy 99.92% || lr [3.125e-06]\n",
      "Epoch[28/50](300/305) || training loss 0.00561 || training accuracy 99.95% || lr [3.125e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.94922527 0.29953198]\n",
      "[Val] acc : 86.23%, loss: 0.62 || best acc : 86.80%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9492252681764005\n",
      "mark: 0.2995319812792512\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df199458e1d435d8b2dcd5c327496e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29/50](100/305) || training loss 0.004649 || training accuracy 100.00% || lr [3.125e-06]\n",
      "Epoch[29/50](200/305) || training loss 0.005165 || training accuracy 99.98% || lr [3.125e-06]\n",
      "Epoch[29/50](300/305) || training loss 0.004592 || training accuracy 99.98% || lr [3.125e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.75675676 0.96066746 0.2698908 ]\n",
      "[Val] acc : 86.83%, loss: 0.64 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9606674612634089\n",
      "mark: 0.2698907956318253\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9dac1f848fe4bedb7a51faf3d9810fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/50](100/305) || training loss 0.005072 || training accuracy 99.95% || lr [1.5625e-06]\n",
      "Epoch[30/50](200/305) || training loss 0.005331 || training accuracy 99.95% || lr [1.5625e-06]\n",
      "Epoch[30/50](300/305) || training loss 0.005191 || training accuracy 99.95% || lr [1.5625e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95399285 0.30109204]\n",
      "[Val] acc : 86.66%, loss: 0.62 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9539928486293207\n",
      "mark: 0.30109204368174725\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0faec212136477d91ca6c1250132ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31/50](100/305) || training loss 0.005398 || training accuracy 99.91% || lr [1.5625e-06]\n",
      "Epoch[31/50](200/305) || training loss 0.005192 || training accuracy 99.94% || lr [1.5625e-06]\n",
      "Epoch[31/50](300/305) || training loss 0.006169 || training accuracy 99.92% || lr [1.5625e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95876043 0.27457098]\n",
      "[Val] acc : 86.72%, loss: 0.64 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9587604290822408\n",
      "mark: 0.2745709828393136\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c3ad05bc644fd6b74043d204c35d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32/50](100/305) || training loss 0.005693 || training accuracy 99.92% || lr [1.5625e-06]\n",
      "Epoch[32/50](200/305) || training loss 0.005998 || training accuracy 99.92% || lr [1.5625e-06]\n",
      "Epoch[32/50](300/305) || training loss 0.005945 || training accuracy 99.89% || lr [1.5625e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.94946365 0.31045242]\n",
      "[Val] acc : 86.39%, loss: 0.62 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9494636471990465\n",
      "mark: 0.31045241809672386\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2283bedac4d4e2093037fe6a0ff8c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33/50](100/305) || training loss 0.006048 || training accuracy 99.92% || lr [1.5625e-06]\n",
      "Epoch[33/50](200/305) || training loss 0.00504 || training accuracy 99.98% || lr [1.5625e-06]\n",
      "Epoch[33/50](300/305) || training loss 0.004516 || training accuracy 99.98% || lr [1.5625e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95041716 0.30889236]\n",
      "[Val] acc : 86.46%, loss: 0.62 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9504171632896306\n",
      "mark: 0.3088923556942278\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b0063a36144394a93927c20c331f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34/50](100/305) || training loss 0.004916 || training accuracy 99.97% || lr [1.5625e-06]\n",
      "Epoch[34/50](200/305) || training loss 0.004355 || training accuracy 99.98% || lr [1.5625e-06]\n",
      "Epoch[34/50](300/305) || training loss 0.004411 || training accuracy 99.97% || lr [1.5625e-06]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95733015 0.28705148]\n",
      "[Val] acc : 86.76%, loss: 0.64 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9573301549463648\n",
      "mark: 0.2870514820592824\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b384f7859a74727bbff079153221bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35/50](100/305) || training loss 0.005306 || training accuracy 99.94% || lr [7.8125e-07]\n",
      "Epoch[35/50](200/305) || training loss 0.006234 || training accuracy 99.89% || lr [7.8125e-07]\n",
      "Epoch[35/50](300/305) || training loss 0.004301 || training accuracy 99.98% || lr [7.8125e-07]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95804529 0.28393136]\n",
      "[Val] acc : 86.78%, loss: 0.64 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9580452920143028\n",
      "mark: 0.2839313572542902\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679caa8187f4493ab590c8126672cdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36/50](100/305) || training loss 0.004232 || training accuracy 99.95% || lr [7.8125e-07]\n",
      "Epoch[36/50](200/305) || training loss 0.004144 || training accuracy 100.00% || lr [7.8125e-07]\n",
      "Epoch[36/50](300/305) || training loss 0.005965 || training accuracy 99.89% || lr [7.8125e-07]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95518474 0.28861154]\n",
      "[Val] acc : 86.60%, loss: 0.64 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9551847437425507\n",
      "mark: 0.28861154446177845\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ba3314b3cb4aba8c0db0b65e3fac0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37/50](100/305) || training loss 0.005554 || training accuracy 99.92% || lr [7.8125e-07]\n",
      "Epoch[37/50](200/305) || training loss 0.003985 || training accuracy 99.98% || lr [7.8125e-07]\n",
      "Epoch[37/50](300/305) || training loss 0.004994 || training accuracy 99.98% || lr [7.8125e-07]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95137068 0.29485179]\n",
      "[Val] acc : 86.35%, loss: 0.63 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9513706793802146\n",
      "mark: 0.2948517940717629\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a83d0964f545a2bf253b29f1f34c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38/50](100/305) || training loss 0.0043 || training accuracy 99.98% || lr [7.8125e-07]\n",
      "Epoch[38/50](200/305) || training loss 0.004386 || training accuracy 99.97% || lr [7.8125e-07]\n",
      "Epoch[38/50](300/305) || training loss 0.005027 || training accuracy 99.98% || lr [7.8125e-07]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.95709178 0.28237129]\n",
      "[Val] acc : 86.68%, loss: 0.64 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9570917759237187\n",
      "mark: 0.2823712948517941\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e20c6567df4948a30341b35939dc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39/50](100/305) || training loss 0.004657 || training accuracy 99.97% || lr [7.8125e-07]\n",
      "Epoch[39/50](200/305) || training loss 0.005202 || training accuracy 99.95% || lr [7.8125e-07]\n",
      "Epoch[39/50](300/305) || training loss 0.005259 || training accuracy 99.92% || lr [7.8125e-07]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.75675676 0.94588796 0.31825273]\n",
      "[Val] acc : 86.19%, loss: 0.62 || best acc : 86.83%, best loss: 0.45\n",
      "nan: 0.7567567567567568\n",
      "text: 0.9458879618593564\n",
      "mark: 0.31825273010920435\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba188f7bbd5440db24816006e0ac167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/50](100/305) || training loss 0.005352 || training accuracy 99.94% || lr [3.90625e-07]\n",
      "Epoch[40/50](200/305) || training loss 0.004295 || training accuracy 99.97% || lr [3.90625e-07]\n",
      "Epoch[40/50](300/305) || training loss 0.004069 || training accuracy 99.95% || lr [3.90625e-07]\n",
      "\n",
      "Calculating validation results...\n",
      "Early Stopping...\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"final-project\", entity=\"medic\", name=f\"KM_{model_name}_text_mark_nan\")\n",
    "\n",
    "name = f'{model_name}_type_and_shape'\n",
    "os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n",
    "\n",
    "counter = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in tqdm(enumerate(train_loader)):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # -- Gradient Accumulation\n",
    "        if (idx+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            train_acc = matches / batch_size / train_log_interval\n",
    "            current_lr = scheduler.get_last_lr()\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "            \n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        label_accuracy, total_label = [0]*num_classes, [0]*num_classes\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            \n",
    "            ## label별 accuracy\n",
    "            for i in range(len(labels)):\n",
    "                total_label[int(labels[i])] += 1\n",
    "                if labels[i] == preds[i]:\n",
    "                    label_accuracy[int(labels[i])] += 1\n",
    "            \n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_df)\n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"results/{name}/best.ckpt\")\n",
    "            best_val_acc = val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        ## 파이썬 배열 나눗셈 https://bearwoong.tistory.com/60\n",
    "        accuracy_by_label = np.array(label_accuracy)/np.array(total_label)\n",
    "        print(f\"accuracy by label: {accuracy_by_label}\")\n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"nan: {accuracy_by_label[0]}\\n\"\n",
    "            f\"text: {accuracy_by_label[1]}\\n\"\n",
    "            f\"mark: {accuracy_by_label[2]}\\n\"\n",
    "        )\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"valid_loss\": val_loss,\n",
    "        \"valid_accuracy\": val_acc,\n",
    "        \"best_loss\": best_val_loss,\n",
    "        \"best_accuracy\": best_val_acc,\n",
    "        \"nan\": accuracy_by_label[0],\n",
    "        \"text\": accuracy_by_label[1],\n",
    "        \"mark\": accuracy_by_label[2],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index()\n",
    "        self.image_id = self.df['품목일련번호']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_id[idx]\n",
    "        image_path = f'/opt/ml/final-project-level3-cv-16/test_data/{image_id}'\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = './test_data'\n",
    "test_list = os.listdir(image_dir)\n",
    "test_list = sorted(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_list)\n",
    "test_df.columns = ['품목일련번호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_dataset = CustomTestDataset(test_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2043, 1.1700, 1.1358,  ..., 0.2967, 0.2282, 0.3138],\n",
       "         [1.2214, 1.1015, 1.1872,  ..., 0.1768, 0.1597, 0.2453],\n",
       "         [1.1358, 1.1187, 1.1358,  ..., 0.2282, 0.2796, 0.2796],\n",
       "         ...,\n",
       "         [0.6392, 0.6221, 0.5878,  ..., 0.6734, 0.5707, 0.6221],\n",
       "         [0.4508, 0.4508, 0.5022,  ..., 0.7077, 0.7933, 0.7591],\n",
       "         [0.5022, 0.5364, 0.5022,  ..., 0.6906, 0.7933, 0.7933]],\n",
       "\n",
       "        [[1.4307, 1.3782, 1.3431,  ..., 0.3452, 0.2402, 0.3803],\n",
       "         [1.4482, 1.3256, 1.4132,  ..., 0.2052, 0.1877, 0.2927],\n",
       "         [1.3431, 1.3081, 1.3431,  ..., 0.2927, 0.3277, 0.3277],\n",
       "         ...,\n",
       "         [0.7129, 0.6779, 0.6429,  ..., 0.7654, 0.6429, 0.6954],\n",
       "         [0.4853, 0.4853, 0.5378,  ..., 0.8179, 0.9230, 0.8880],\n",
       "         [0.5553, 0.5728, 0.5203,  ..., 0.8004, 0.9230, 0.9230]],\n",
       "\n",
       "        [[1.5245, 1.5071, 1.4548,  ..., 0.4439, 0.3219, 0.4439],\n",
       "         [1.5768, 1.4374, 1.5420,  ..., 0.3045, 0.2696, 0.3742],\n",
       "         [1.4722, 1.4374, 1.4722,  ..., 0.3742, 0.4091, 0.4091],\n",
       "         ...,\n",
       "         [0.8797, 0.8448, 0.7925,  ..., 0.8797, 0.7751, 0.8099],\n",
       "         [0.6182, 0.6356, 0.6879,  ..., 0.9668, 1.0714, 1.0365],\n",
       "         [0.7054, 0.7228, 0.6879,  ..., 0.9494, 1.0539, 1.0714]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = next(iter(test_dataset))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv_stem.weight\", \"blocks.0.0.conv_dw.weight\", \"blocks.0.0.bn1.weight\", \"blocks.0.0.bn1.bias\", \"blocks.0.0.bn1.running_mean\", \"blocks.0.0.bn1.running_var\", \"blocks.0.0.bn1.num_batches_tracked\", \"blocks.0.0.se.conv_reduce.weight\", \"blocks.0.0.se.conv_reduce.bias\", \"blocks.0.0.se.conv_expand.weight\", \"blocks.0.0.se.conv_expand.bias\", \"blocks.0.0.conv_pw.weight\", \"blocks.0.0.bn2.weight\", \"blocks.0.0.bn2.bias\", \"blocks.0.0.bn2.running_mean\", \"blocks.0.0.bn2.running_var\", \"blocks.0.0.bn2.num_batches_tracked\", \"blocks.0.1.conv_dw.weight\", \"blocks.0.1.bn1.weight\", \"blocks.0.1.bn1.bias\", \"blocks.0.1.bn1.running_mean\", \"blocks.0.1.bn1.running_var\", \"blocks.0.1.bn1.num_batches_tracked\", \"blocks.0.1.se.conv_reduce.weight\", \"blocks.0.1.se.conv_reduce.bias\", \"blocks.0.1.se.conv_expand.weight\", \"blocks.0.1.se.conv_expand.bias\", \"blocks.0.1.conv_pw.weight\", \"blocks.0.1.bn2.weight\", \"blocks.0.1.bn2.bias\", \"blocks.0.1.bn2.running_mean\", \"blocks.0.1.bn2.running_var\", \"blocks.0.1.bn2.num_batches_tracked\", \"blocks.1.0.conv_pw.weight\", \"blocks.1.0.bn1.weight\", \"blocks.1.0.bn1.bias\", \"blocks.1.0.bn1.running_mean\", \"blocks.1.0.bn1.running_var\", \"blocks.1.0.bn1.num_batches_tracked\", \"blocks.1.0.conv_dw.weight\", \"blocks.1.0.bn2.weight\", \"blocks.1.0.bn2.bias\", \"blocks.1.0.bn2.running_mean\", \"blocks.1.0.bn2.running_var\", \"blocks.1.0.bn2.num_batches_tracked\", \"blocks.1.0.se.conv_reduce.weight\", \"blocks.1.0.se.conv_reduce.bias\", \"blocks.1.0.se.conv_expand.weight\", \"blocks.1.0.se.conv_expand.bias\", \"blocks.1.0.conv_pwl.weight\", \"blocks.1.0.bn3.weight\", \"blocks.1.0.bn3.bias\", \"blocks.1.0.bn3.running_mean\", \"blocks.1.0.bn3.running_var\", \"blocks.1.0.bn3.num_batches_tracked\", \"blocks.1.1.conv_pw.weight\", \"blocks.1.1.bn1.weight\", \"blocks.1.1.bn1.bias\", \"blocks.1.1.bn1.running_mean\", \"blocks.1.1.bn1.running_var\", \"blocks.1.1.bn1.num_batches_tracked\", \"blocks.1.1.conv_dw.weight\", \"blocks.1.1.bn2.weight\", \"blocks.1.1.bn2.bias\", \"blocks.1.1.bn2.running_mean\", \"blocks.1.1.bn2.running_var\", \"blocks.1.1.bn2.num_batches_tracked\", \"blocks.1.1.se.conv_reduce.weight\", \"blocks.1.1.se.conv_reduce.bias\", \"blocks.1.1.se.conv_expand.weight\", \"blocks.1.1.se.conv_expand.bias\", \"blocks.1.1.conv_pwl.weight\", \"blocks.1.1.bn3.weight\", \"blocks.1.1.bn3.bias\", \"blocks.1.1.bn3.running_mean\", \"blocks.1.1.bn3.running_var\", \"blocks.1.1.bn3.num_batches_tracked\", \"blocks.1.2.conv_pw.weight\", \"blocks.1.2.bn1.weight\", \"blocks.1.2.bn1.bias\", \"blocks.1.2.bn1.running_mean\", \"blocks.1.2.bn1.running_var\", \"blocks.1.2.bn1.num_batches_tracked\", \"blocks.1.2.conv_dw.weight\", \"blocks.1.2.bn2.weight\", \"blocks.1.2.bn2.bias\", \"blocks.1.2.bn2.running_mean\", \"blocks.1.2.bn2.running_var\", \"blocks.1.2.bn2.num_batches_tracked\", \"blocks.1.2.se.conv_reduce.weight\", \"blocks.1.2.se.conv_reduce.bias\", \"blocks.1.2.se.conv_expand.weight\", \"blocks.1.2.se.conv_expand.bias\", \"blocks.1.2.conv_pwl.weight\", \"blocks.1.2.bn3.weight\", \"blocks.1.2.bn3.bias\", \"blocks.1.2.bn3.running_mean\", \"blocks.1.2.bn3.running_var\", \"blocks.1.2.bn3.num_batches_tracked\", \"blocks.2.0.conv_pw.weight\", \"blocks.2.0.bn1.weight\", \"blocks.2.0.bn1.bias\", \"blocks.2.0.bn1.running_mean\", \"blocks.2.0.bn1.running_var\", \"blocks.2.0.bn1.num_batches_tracked\", \"blocks.2.0.conv_dw.weight\", \"blocks.2.0.bn2.weight\", \"blocks.2.0.bn2.bias\", \"blocks.2.0.bn2.running_mean\", \"blocks.2.0.bn2.running_var\", \"blocks.2.0.bn2.num_batches_tracked\", \"blocks.2.0.se.conv_reduce.weight\", \"blocks.2.0.se.conv_reduce.bias\", \"blocks.2.0.se.conv_expand.weight\", \"blocks.2.0.se.conv_expand.bias\", \"blocks.2.0.conv_pwl.weight\", \"blocks.2.0.bn3.weight\", \"blocks.2.0.bn3.bias\", \"blocks.2.0.bn3.running_mean\", \"blocks.2.0.bn3.running_var\", \"blocks.2.0.bn3.num_batches_tracked\", \"blocks.2.1.conv_pw.weight\", \"blocks.2.1.bn1.weight\", \"blocks.2.1.bn1.bias\", \"blocks.2.1.bn1.running_mean\", \"blocks.2.1.bn1.running_var\", \"blocks.2.1.bn1.num_batches_tracked\", \"blocks.2.1.conv_dw.weight\", \"blocks.2.1.bn2.weight\", \"blocks.2.1.bn2.bias\", \"blocks.2.1.bn2.running_mean\", \"blocks.2.1.bn2.running_var\", \"blocks.2.1.bn2.num_batches_tracked\", \"blocks.2.1.se.conv_reduce.weight\", \"blocks.2.1.se.conv_reduce.bias\", \"blocks.2.1.se.conv_expand.weight\", \"blocks.2.1.se.conv_expand.bias\", \"blocks.2.1.conv_pwl.weight\", \"blocks.2.1.bn3.weight\", \"blocks.2.1.bn3.bias\", \"blocks.2.1.bn3.running_mean\", \"blocks.2.1.bn3.running_var\", \"blocks.2.1.bn3.num_batches_tracked\", \"blocks.2.2.conv_pw.weight\", \"blocks.2.2.bn1.weight\", \"blocks.2.2.bn1.bias\", \"blocks.2.2.bn1.running_mean\", \"blocks.2.2.bn1.running_var\", \"blocks.2.2.bn1.num_batches_tracked\", \"blocks.2.2.conv_dw.weight\", \"blocks.2.2.bn2.weight\", \"blocks.2.2.bn2.bias\", \"blocks.2.2.bn2.running_mean\", \"blocks.2.2.bn2.running_var\", \"blocks.2.2.bn2.num_batches_tracked\", \"blocks.2.2.se.conv_reduce.weight\", \"blocks.2.2.se.conv_reduce.bias\", \"blocks.2.2.se.conv_expand.weight\", \"blocks.2.2.se.conv_expand.bias\", \"blocks.2.2.conv_pwl.weight\", \"blocks.2.2.bn3.weight\", \"blocks.2.2.bn3.bias\", \"blocks.2.2.bn3.running_mean\", \"blocks.2.2.bn3.running_var\", \"blocks.2.2.bn3.num_batches_tracked\", \"blocks.3.0.conv_pw.weight\", \"blocks.3.0.bn1.weight\", \"blocks.3.0.bn1.bias\", \"blocks.3.0.bn1.running_mean\", \"blocks.3.0.bn1.running_var\", \"blocks.3.0.bn1.num_batches_tracked\", \"blocks.3.0.conv_dw.weight\", \"blocks.3.0.bn2.weight\", \"blocks.3.0.bn2.bias\", \"blocks.3.0.bn2.running_mean\", \"blocks.3.0.bn2.running_var\", \"blocks.3.0.bn2.num_batches_tracked\", \"blocks.3.0.se.conv_reduce.weight\", \"blocks.3.0.se.conv_reduce.bias\", \"blocks.3.0.se.conv_expand.weight\", \"blocks.3.0.se.conv_expand.bias\", \"blocks.3.0.conv_pwl.weight\", \"blocks.3.0.bn3.weight\", \"blocks.3.0.bn3.bias\", \"blocks.3.0.bn3.running_mean\", \"blocks.3.0.bn3.running_var\", \"blocks.3.0.bn3.num_batches_tracked\", \"blocks.3.1.conv_pw.weight\", \"blocks.3.1.bn1.weight\", \"blocks.3.1.bn1.bias\", \"blocks.3.1.bn1.running_mean\", \"blocks.3.1.bn1.running_var\", \"blocks.3.1.bn1.num_batches_tracked\", \"blocks.3.1.conv_dw.weight\", \"blocks.3.1.bn2.weight\", \"blocks.3.1.bn2.bias\", \"blocks.3.1.bn2.running_mean\", \"blocks.3.1.bn2.running_var\", \"blocks.3.1.bn2.num_batches_tracked\", \"blocks.3.1.se.conv_reduce.weight\", \"blocks.3.1.se.conv_reduce.bias\", \"blocks.3.1.se.conv_expand.weight\", \"blocks.3.1.se.conv_expand.bias\", \"blocks.3.1.conv_pwl.weight\", \"blocks.3.1.bn3.weight\", \"blocks.3.1.bn3.bias\", \"blocks.3.1.bn3.running_mean\", \"blocks.3.1.bn3.running_var\", \"blocks.3.1.bn3.num_batches_tracked\", \"blocks.3.2.conv_pw.weight\", \"blocks.3.2.bn1.weight\", \"blocks.3.2.bn1.bias\", \"blocks.3.2.bn1.running_mean\", \"blocks.3.2.bn1.running_var\", \"blocks.3.2.bn1.num_batches_tracked\", \"blocks.3.2.conv_dw.weight\", \"blocks.3.2.bn2.weight\", \"blocks.3.2.bn2.bias\", \"blocks.3.2.bn2.running_mean\", \"blocks.3.2.bn2.running_var\", \"blocks.3.2.bn2.num_batches_tracked\", \"blocks.3.2.se.conv_reduce.weight\", \"blocks.3.2.se.conv_reduce.bias\", \"blocks.3.2.se.conv_expand.weight\", \"blocks.3.2.se.conv_expand.bias\", \"blocks.3.2.conv_pwl.weight\", \"blocks.3.2.bn3.weight\", \"blocks.3.2.bn3.bias\", \"blocks.3.2.bn3.running_mean\", \"blocks.3.2.bn3.running_var\", \"blocks.3.2.bn3.num_batches_tracked\", \"blocks.3.3.conv_pw.weight\", \"blocks.3.3.bn1.weight\", \"blocks.3.3.bn1.bias\", \"blocks.3.3.bn1.running_mean\", \"blocks.3.3.bn1.running_var\", \"blocks.3.3.bn1.num_batches_tracked\", \"blocks.3.3.conv_dw.weight\", \"blocks.3.3.bn2.weight\", \"blocks.3.3.bn2.bias\", \"blocks.3.3.bn2.running_mean\", \"blocks.3.3.bn2.running_var\", \"blocks.3.3.bn2.num_batches_tracked\", \"blocks.3.3.se.conv_reduce.weight\", \"blocks.3.3.se.conv_reduce.bias\", \"blocks.3.3.se.conv_expand.weight\", \"blocks.3.3.se.conv_expand.bias\", \"blocks.3.3.conv_pwl.weight\", \"blocks.3.3.bn3.weight\", \"blocks.3.3.bn3.bias\", \"blocks.3.3.bn3.running_mean\", \"blocks.3.3.bn3.running_var\", \"blocks.3.3.bn3.num_batches_tracked\", \"blocks.4.0.conv_pw.weight\", \"blocks.4.0.bn1.weight\", \"blocks.4.0.bn1.bias\", \"blocks.4.0.bn1.running_mean\", \"blocks.4.0.bn1.running_var\", \"blocks.4.0.bn1.num_batches_tracked\", \"blocks.4.0.conv_dw.weight\", \"blocks.4.0.bn2.weight\", \"blocks.4.0.bn2.bias\", \"blocks.4.0.bn2.running_mean\", \"blocks.4.0.bn2.running_var\", \"blocks.4.0.bn2.num_batches_tracked\", \"blocks.4.0.se.conv_reduce.weight\", \"blocks.4.0.se.conv_reduce.bias\", \"blocks.4.0.se.conv_expand.weight\", \"blocks.4.0.se.conv_expand.bias\", \"blocks.4.0.conv_pwl.weight\", \"blocks.4.0.bn3.weight\", \"blocks.4.0.bn3.bias\", \"blocks.4.0.bn3.running_mean\", \"blocks.4.0.bn3.running_var\", \"blocks.4.0.bn3.num_batches_tracked\", \"blocks.4.1.conv_pw.weight\", \"blocks.4.1.bn1.weight\", \"blocks.4.1.bn1.bias\", \"blocks.4.1.bn1.running_mean\", \"blocks.4.1.bn1.running_var\", \"blocks.4.1.bn1.num_batches_tracked\", \"blocks.4.1.conv_dw.weight\", \"blocks.4.1.bn2.weight\", \"blocks.4.1.bn2.bias\", \"blocks.4.1.bn2.running_mean\", \"blocks.4.1.bn2.running_var\", \"blocks.4.1.bn2.num_batches_tracked\", \"blocks.4.1.se.conv_reduce.weight\", \"blocks.4.1.se.conv_reduce.bias\", \"blocks.4.1.se.conv_expand.weight\", \"blocks.4.1.se.conv_expand.bias\", \"blocks.4.1.conv_pwl.weight\", \"blocks.4.1.bn3.weight\", \"blocks.4.1.bn3.bias\", \"blocks.4.1.bn3.running_mean\", \"blocks.4.1.bn3.running_var\", \"blocks.4.1.bn3.num_batches_tracked\", \"blocks.4.2.conv_pw.weight\", \"blocks.4.2.bn1.weight\", \"blocks.4.2.bn1.bias\", \"blocks.4.2.bn1.running_mean\", \"blocks.4.2.bn1.running_var\", \"blocks.4.2.bn1.num_batches_tracked\", \"blocks.4.2.conv_dw.weight\", \"blocks.4.2.bn2.weight\", \"blocks.4.2.bn2.bias\", \"blocks.4.2.bn2.running_mean\", \"blocks.4.2.bn2.running_var\", \"blocks.4.2.bn2.num_batches_tracked\", \"blocks.4.2.se.conv_reduce.weight\", \"blocks.4.2.se.conv_reduce.bias\", \"blocks.4.2.se.conv_expand.weight\", \"blocks.4.2.se.conv_expand.bias\", \"blocks.4.2.conv_pwl.weight\", \"blocks.4.2.bn3.weight\", \"blocks.4.2.bn3.bias\", \"blocks.4.2.bn3.running_mean\", \"blocks.4.2.bn3.running_var\", \"blocks.4.2.bn3.num_batches_tracked\", \"blocks.4.3.conv_pw.weight\", \"blocks.4.3.bn1.weight\", \"blocks.4.3.bn1.bias\", \"blocks.4.3.bn1.running_mean\", \"blocks.4.3.bn1.running_var\", \"blocks.4.3.bn1.num_batches_tracked\", \"blocks.4.3.conv_dw.weight\", \"blocks.4.3.bn2.weight\", \"blocks.4.3.bn2.bias\", \"blocks.4.3.bn2.running_mean\", \"blocks.4.3.bn2.running_var\", \"blocks.4.3.bn2.num_batches_tracked\", \"blocks.4.3.se.conv_reduce.weight\", \"blocks.4.3.se.conv_reduce.bias\", \"blocks.4.3.se.conv_expand.weight\", \"blocks.4.3.se.conv_expand.bias\", \"blocks.4.3.conv_pwl.weight\", \"blocks.4.3.bn3.weight\", \"blocks.4.3.bn3.bias\", \"blocks.4.3.bn3.running_mean\", \"blocks.4.3.bn3.running_var\", \"blocks.4.3.bn3.num_batches_tracked\", \"blocks.5.0.conv_pw.weight\", \"blocks.5.0.bn1.weight\", \"blocks.5.0.bn1.bias\", \"blocks.5.0.bn1.running_mean\", \"blocks.5.0.bn1.running_var\", \"blocks.5.0.bn1.num_batches_tracked\", \"blocks.5.0.conv_dw.weight\", \"blocks.5.0.bn2.weight\", \"blocks.5.0.bn2.bias\", \"blocks.5.0.bn2.running_mean\", \"blocks.5.0.bn2.running_var\", \"blocks.5.0.bn2.num_batches_tracked\", \"blocks.5.0.se.conv_reduce.weight\", \"blocks.5.0.se.conv_reduce.bias\", \"blocks.5.0.se.conv_expand.weight\", \"blocks.5.0.se.conv_expand.bias\", \"blocks.5.0.conv_pwl.weight\", \"blocks.5.0.bn3.weight\", \"blocks.5.0.bn3.bias\", \"blocks.5.0.bn3.running_mean\", \"blocks.5.0.bn3.running_var\", \"blocks.5.0.bn3.num_batches_tracked\", \"blocks.5.1.conv_pw.weight\", \"blocks.5.1.bn1.weight\", \"blocks.5.1.bn1.bias\", \"blocks.5.1.bn1.running_mean\", \"blocks.5.1.bn1.running_var\", \"blocks.5.1.bn1.num_batches_tracked\", \"blocks.5.1.conv_dw.weight\", \"blocks.5.1.bn2.weight\", \"blocks.5.1.bn2.bias\", \"blocks.5.1.bn2.running_mean\", \"blocks.5.1.bn2.running_var\", \"blocks.5.1.bn2.num_batches_tracked\", \"blocks.5.1.se.conv_reduce.weight\", \"blocks.5.1.se.conv_reduce.bias\", \"blocks.5.1.se.conv_expand.weight\", \"blocks.5.1.se.conv_expand.bias\", \"blocks.5.1.conv_pwl.weight\", \"blocks.5.1.bn3.weight\", \"blocks.5.1.bn3.bias\", \"blocks.5.1.bn3.running_mean\", \"blocks.5.1.bn3.running_var\", \"blocks.5.1.bn3.num_batches_tracked\", \"blocks.5.2.conv_pw.weight\", \"blocks.5.2.bn1.weight\", \"blocks.5.2.bn1.bias\", \"blocks.5.2.bn1.running_mean\", \"blocks.5.2.bn1.running_var\", \"blocks.5.2.bn1.num_batches_tracked\", \"blocks.5.2.conv_dw.weight\", \"blocks.5.2.bn2.weight\", \"blocks.5.2.bn2.bias\", \"blocks.5.2.bn2.running_mean\", \"blocks.5.2.bn2.running_var\", \"blocks.5.2.bn2.num_batches_tracked\", \"blocks.5.2.se.conv_reduce.weight\", \"blocks.5.2.se.conv_reduce.bias\", \"blocks.5.2.se.conv_expand.weight\", \"blocks.5.2.se.conv_expand.bias\", \"blocks.5.2.conv_pwl.weight\", \"blocks.5.2.bn3.weight\", \"blocks.5.2.bn3.bias\", \"blocks.5.2.bn3.running_mean\", \"blocks.5.2.bn3.running_var\", \"blocks.5.2.bn3.num_batches_tracked\", \"blocks.5.3.conv_pw.weight\", \"blocks.5.3.bn1.weight\", \"blocks.5.3.bn1.bias\", \"blocks.5.3.bn1.running_mean\", \"blocks.5.3.bn1.running_var\", \"blocks.5.3.bn1.num_batches_tracked\", \"blocks.5.3.conv_dw.weight\", \"blocks.5.3.bn2.weight\", \"blocks.5.3.bn2.bias\", \"blocks.5.3.bn2.running_mean\", \"blocks.5.3.bn2.running_var\", \"blocks.5.3.bn2.num_batches_tracked\", \"blocks.5.3.se.conv_reduce.weight\", \"blocks.5.3.se.conv_reduce.bias\", \"blocks.5.3.se.conv_expand.weight\", \"blocks.5.3.se.conv_expand.bias\", \"blocks.5.3.conv_pwl.weight\", \"blocks.5.3.bn3.weight\", \"blocks.5.3.bn3.bias\", \"blocks.5.3.bn3.running_mean\", \"blocks.5.3.bn3.running_var\", \"blocks.5.3.bn3.num_batches_tracked\", \"blocks.5.4.conv_pw.weight\", \"blocks.5.4.bn1.weight\", \"blocks.5.4.bn1.bias\", \"blocks.5.4.bn1.running_mean\", \"blocks.5.4.bn1.running_var\", \"blocks.5.4.bn1.num_batches_tracked\", \"blocks.5.4.conv_dw.weight\", \"blocks.5.4.bn2.weight\", \"blocks.5.4.bn2.bias\", \"blocks.5.4.bn2.running_mean\", \"blocks.5.4.bn2.running_var\", \"blocks.5.4.bn2.num_batches_tracked\", \"blocks.5.4.se.conv_reduce.weight\", \"blocks.5.4.se.conv_reduce.bias\", \"blocks.5.4.se.conv_expand.weight\", \"blocks.5.4.se.conv_expand.bias\", \"blocks.5.4.conv_pwl.weight\", \"blocks.5.4.bn3.weight\", \"blocks.5.4.bn3.bias\", \"blocks.5.4.bn3.running_mean\", \"blocks.5.4.bn3.running_var\", \"blocks.5.4.bn3.num_batches_tracked\", \"blocks.6.0.conv_pw.weight\", \"blocks.6.0.bn1.weight\", \"blocks.6.0.bn1.bias\", \"blocks.6.0.bn1.running_mean\", \"blocks.6.0.bn1.running_var\", \"blocks.6.0.bn1.num_batches_tracked\", \"blocks.6.0.conv_dw.weight\", \"blocks.6.0.bn2.weight\", \"blocks.6.0.bn2.bias\", \"blocks.6.0.bn2.running_mean\", \"blocks.6.0.bn2.running_var\", \"blocks.6.0.bn2.num_batches_tracked\", \"blocks.6.0.se.conv_reduce.weight\", \"blocks.6.0.se.conv_reduce.bias\", \"blocks.6.0.se.conv_expand.weight\", \"blocks.6.0.se.conv_expand.bias\", \"blocks.6.0.conv_pwl.weight\", \"blocks.6.0.bn3.weight\", \"blocks.6.0.bn3.bias\", \"blocks.6.0.bn3.running_mean\", \"blocks.6.0.bn3.running_var\", \"blocks.6.0.bn3.num_batches_tracked\", \"blocks.6.1.conv_pw.weight\", \"blocks.6.1.bn1.weight\", \"blocks.6.1.bn1.bias\", \"blocks.6.1.bn1.running_mean\", \"blocks.6.1.bn1.running_var\", \"blocks.6.1.bn1.num_batches_tracked\", \"blocks.6.1.conv_dw.weight\", \"blocks.6.1.bn2.weight\", \"blocks.6.1.bn2.bias\", \"blocks.6.1.bn2.running_mean\", \"blocks.6.1.bn2.running_var\", \"blocks.6.1.bn2.num_batches_tracked\", \"blocks.6.1.se.conv_reduce.weight\", \"blocks.6.1.se.conv_reduce.bias\", \"blocks.6.1.se.conv_expand.weight\", \"blocks.6.1.se.conv_expand.bias\", \"blocks.6.1.conv_pwl.weight\", \"blocks.6.1.bn3.weight\", \"blocks.6.1.bn3.bias\", \"blocks.6.1.bn3.running_mean\", \"blocks.6.1.bn3.running_var\", \"blocks.6.1.bn3.num_batches_tracked\", \"conv_head.weight\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"classifier.weight\", \"classifier.bias\". \n\tsize mismatch for bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[1;32m      6\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1047\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1052\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"conv_stem.weight\", \"blocks.0.0.conv_dw.weight\", \"blocks.0.0.bn1.weight\", \"blocks.0.0.bn1.bias\", \"blocks.0.0.bn1.running_mean\", \"blocks.0.0.bn1.running_var\", \"blocks.0.0.bn1.num_batches_tracked\", \"blocks.0.0.se.conv_reduce.weight\", \"blocks.0.0.se.conv_reduce.bias\", \"blocks.0.0.se.conv_expand.weight\", \"blocks.0.0.se.conv_expand.bias\", \"blocks.0.0.conv_pw.weight\", \"blocks.0.0.bn2.weight\", \"blocks.0.0.bn2.bias\", \"blocks.0.0.bn2.running_mean\", \"blocks.0.0.bn2.running_var\", \"blocks.0.0.bn2.num_batches_tracked\", \"blocks.0.1.conv_dw.weight\", \"blocks.0.1.bn1.weight\", \"blocks.0.1.bn1.bias\", \"blocks.0.1.bn1.running_mean\", \"blocks.0.1.bn1.running_var\", \"blocks.0.1.bn1.num_batches_tracked\", \"blocks.0.1.se.conv_reduce.weight\", \"blocks.0.1.se.conv_reduce.bias\", \"blocks.0.1.se.conv_expand.weight\", \"blocks.0.1.se.conv_expand.bias\", \"blocks.0.1.conv_pw.weight\", \"blocks.0.1.bn2.weight\", \"blocks.0.1.bn2.bias\", \"blocks.0.1.bn2.running_mean\", \"blocks.0.1.bn2.running_var\", \"blocks.0.1.bn2.num_batches_tracked\", \"blocks.1.0.conv_pw.weight\", \"blocks.1.0.bn1.weight\", \"blocks.1.0.bn1.bias\", \"blocks.1.0.bn1.running_mean\", \"blocks.1.0.bn1.running_var\", \"blocks.1.0.bn1.num_batches_tracked\", \"blocks.1.0.conv_dw.weight\", \"blocks.1.0.bn2.weight\", \"blocks.1.0.bn2.bias\", \"blocks.1.0.bn2.running_mean\", \"blocks.1.0.bn2.running_var\", \"blocks.1.0.bn2.num_batches_tracked\", \"blocks.1.0.se.conv_reduce.weight\", \"blocks.1.0.se.conv_reduce.bias\", \"blocks.1.0.se.conv_expand.weight\", \"blocks.1.0.se.conv_expand.bias\", \"blocks.1.0.conv_pwl.weight\", \"blocks.1.0.bn3.weight\", \"blocks.1.0.bn3.bias\", \"blocks.1.0.bn3.running_mean\", \"blocks.1.0.bn3.running_var\", \"blocks.1.0.bn3.num_batches_tracked\", \"blocks.1.1.conv_pw.weight\", \"blocks.1.1.bn1.weight\", \"blocks.1.1.bn1.bias\", \"blocks.1.1.bn1.running_mean\", \"blocks.1.1.bn1.running_var\", \"blocks.1.1.bn1.num_batches_tracked\", \"blocks.1.1.conv_dw.weight\", \"blocks.1.1.bn2.weight\", \"blocks.1.1.bn2.bias\", \"blocks.1.1.bn2.running_mean\", \"blocks.1.1.bn2.running_var\", \"blocks.1.1.bn2.num_batches_tracked\", \"blocks.1.1.se.conv_reduce.weight\", \"blocks.1.1.se.conv_reduce.bias\", \"blocks.1.1.se.conv_expand.weight\", \"blocks.1.1.se.conv_expand.bias\", \"blocks.1.1.conv_pwl.weight\", \"blocks.1.1.bn3.weight\", \"blocks.1.1.bn3.bias\", \"blocks.1.1.bn3.running_mean\", \"blocks.1.1.bn3.running_var\", \"blocks.1.1.bn3.num_batches_tracked\", \"blocks.1.2.conv_pw.weight\", \"blocks.1.2.bn1.weight\", \"blocks.1.2.bn1.bias\", \"blocks.1.2.bn1.running_mean\", \"blocks.1.2.bn1.running_var\", \"blocks.1.2.bn1.num_batches_tracked\", \"blocks.1.2.conv_dw.weight\", \"blocks.1.2.bn2.weight\", \"blocks.1.2.bn2.bias\", \"blocks.1.2.bn2.running_mean\", \"blocks.1.2.bn2.running_var\", \"blocks.1.2.bn2.num_batches_tracked\", \"blocks.1.2.se.conv_reduce.weight\", \"blocks.1.2.se.conv_reduce.bias\", \"blocks.1.2.se.conv_expand.weight\", \"blocks.1.2.se.conv_expand.bias\", \"blocks.1.2.conv_pwl.weight\", \"blocks.1.2.bn3.weight\", \"blocks.1.2.bn3.bias\", \"blocks.1.2.bn3.running_mean\", \"blocks.1.2.bn3.running_var\", \"blocks.1.2.bn3.num_batches_tracked\", \"blocks.2.0.conv_pw.weight\", \"blocks.2.0.bn1.weight\", \"blocks.2.0.bn1.bias\", \"blocks.2.0.bn1.running_mean\", \"blocks.2.0.bn1.running_var\", \"blocks.2.0.bn1.num_batches_tracked\", \"blocks.2.0.conv_dw.weight\", \"blocks.2.0.bn2.weight\", \"blocks.2.0.bn2.bias\", \"blocks.2.0.bn2.running_mean\", \"blocks.2.0.bn2.running_var\", \"blocks.2.0.bn2.num_batches_tracked\", \"blocks.2.0.se.conv_reduce.weight\", \"blocks.2.0.se.conv_reduce.bias\", \"blocks.2.0.se.conv_expand.weight\", \"blocks.2.0.se.conv_expand.bias\", \"blocks.2.0.conv_pwl.weight\", \"blocks.2.0.bn3.weight\", \"blocks.2.0.bn3.bias\", \"blocks.2.0.bn3.running_mean\", \"blocks.2.0.bn3.running_var\", \"blocks.2.0.bn3.num_batches_tracked\", \"blocks.2.1.conv_pw.weight\", \"blocks.2.1.bn1.weight\", \"blocks.2.1.bn1.bias\", \"blocks.2.1.bn1.running_mean\", \"blocks.2.1.bn1.running_var\", \"blocks.2.1.bn1.num_batches_tracked\", \"blocks.2.1.conv_dw.weight\", \"blocks.2.1.bn2.weight\", \"blocks.2.1.bn2.bias\", \"blocks.2.1.bn2.running_mean\", \"blocks.2.1.bn2.running_var\", \"blocks.2.1.bn2.num_batches_tracked\", \"blocks.2.1.se.conv_reduce.weight\", \"blocks.2.1.se.conv_reduce.bias\", \"blocks.2.1.se.conv_expand.weight\", \"blocks.2.1.se.conv_expand.bias\", \"blocks.2.1.conv_pwl.weight\", \"blocks.2.1.bn3.weight\", \"blocks.2.1.bn3.bias\", \"blocks.2.1.bn3.running_mean\", \"blocks.2.1.bn3.running_var\", \"blocks.2.1.bn3.num_batches_tracked\", \"blocks.2.2.conv_pw.weight\", \"blocks.2.2.bn1.weight\", \"blocks.2.2.bn1.bias\", \"blocks.2.2.bn1.running_mean\", \"blocks.2.2.bn1.running_var\", \"blocks.2.2.bn1.num_batches_tracked\", \"blocks.2.2.conv_dw.weight\", \"blocks.2.2.bn2.weight\", \"blocks.2.2.bn2.bias\", \"blocks.2.2.bn2.running_mean\", \"blocks.2.2.bn2.running_var\", \"blocks.2.2.bn2.num_batches_tracked\", \"blocks.2.2.se.conv_reduce.weight\", \"blocks.2.2.se.conv_reduce.bias\", \"blocks.2.2.se.conv_expand.weight\", \"blocks.2.2.se.conv_expand.bias\", \"blocks.2.2.conv_pwl.weight\", \"blocks.2.2.bn3.weight\", \"blocks.2.2.bn3.bias\", \"blocks.2.2.bn3.running_mean\", \"blocks.2.2.bn3.running_var\", \"blocks.2.2.bn3.num_batches_tracked\", \"blocks.3.0.conv_pw.weight\", \"blocks.3.0.bn1.weight\", \"blocks.3.0.bn1.bias\", \"blocks.3.0.bn1.running_mean\", \"blocks.3.0.bn1.running_var\", \"blocks.3.0.bn1.num_batches_tracked\", \"blocks.3.0.conv_dw.weight\", \"blocks.3.0.bn2.weight\", \"blocks.3.0.bn2.bias\", \"blocks.3.0.bn2.running_mean\", \"blocks.3.0.bn2.running_var\", \"blocks.3.0.bn2.num_batches_tracked\", \"blocks.3.0.se.conv_reduce.weight\", \"blocks.3.0.se.conv_reduce.bias\", \"blocks.3.0.se.conv_expand.weight\", \"blocks.3.0.se.conv_expand.bias\", \"blocks.3.0.conv_pwl.weight\", \"blocks.3.0.bn3.weight\", \"blocks.3.0.bn3.bias\", \"blocks.3.0.bn3.running_mean\", \"blocks.3.0.bn3.running_var\", \"blocks.3.0.bn3.num_batches_tracked\", \"blocks.3.1.conv_pw.weight\", \"blocks.3.1.bn1.weight\", \"blocks.3.1.bn1.bias\", \"blocks.3.1.bn1.running_mean\", \"blocks.3.1.bn1.running_var\", \"blocks.3.1.bn1.num_batches_tracked\", \"blocks.3.1.conv_dw.weight\", \"blocks.3.1.bn2.weight\", \"blocks.3.1.bn2.bias\", \"blocks.3.1.bn2.running_mean\", \"blocks.3.1.bn2.running_var\", \"blocks.3.1.bn2.num_batches_tracked\", \"blocks.3.1.se.conv_reduce.weight\", \"blocks.3.1.se.conv_reduce.bias\", \"blocks.3.1.se.conv_expand.weight\", \"blocks.3.1.se.conv_expand.bias\", \"blocks.3.1.conv_pwl.weight\", \"blocks.3.1.bn3.weight\", \"blocks.3.1.bn3.bias\", \"blocks.3.1.bn3.running_mean\", \"blocks.3.1.bn3.running_var\", \"blocks.3.1.bn3.num_batches_tracked\", \"blocks.3.2.conv_pw.weight\", \"blocks.3.2.bn1.weight\", \"blocks.3.2.bn1.bias\", \"blocks.3.2.bn1.running_mean\", \"blocks.3.2.bn1.running_var\", \"blocks.3.2.bn1.num_batches_tracked\", \"blocks.3.2.conv_dw.weight\", \"blocks.3.2.bn2.weight\", \"blocks.3.2.bn2.bias\", \"blocks.3.2.bn2.running_mean\", \"blocks.3.2.bn2.running_var\", \"blocks.3.2.bn2.num_batches_tracked\", \"blocks.3.2.se.conv_reduce.weight\", \"blocks.3.2.se.conv_reduce.bias\", \"blocks.3.2.se.conv_expand.weight\", \"blocks.3.2.se.conv_expand.bias\", \"blocks.3.2.conv_pwl.weight\", \"blocks.3.2.bn3.weight\", \"blocks.3.2.bn3.bias\", \"blocks.3.2.bn3.running_mean\", \"blocks.3.2.bn3.running_var\", \"blocks.3.2.bn3.num_batches_tracked\", \"blocks.3.3.conv_pw.weight\", \"blocks.3.3.bn1.weight\", \"blocks.3.3.bn1.bias\", \"blocks.3.3.bn1.running_mean\", \"blocks.3.3.bn1.running_var\", \"blocks.3.3.bn1.num_batches_tracked\", \"blocks.3.3.conv_dw.weight\", \"blocks.3.3.bn2.weight\", \"blocks.3.3.bn2.bias\", \"blocks.3.3.bn2.running_mean\", \"blocks.3.3.bn2.running_var\", \"blocks.3.3.bn2.num_batches_tracked\", \"blocks.3.3.se.conv_reduce.weight\", \"blocks.3.3.se.conv_reduce.bias\", \"blocks.3.3.se.conv_expand.weight\", \"blocks.3.3.se.conv_expand.bias\", \"blocks.3.3.conv_pwl.weight\", \"blocks.3.3.bn3.weight\", \"blocks.3.3.bn3.bias\", \"blocks.3.3.bn3.running_mean\", \"blocks.3.3.bn3.running_var\", \"blocks.3.3.bn3.num_batches_tracked\", \"blocks.4.0.conv_pw.weight\", \"blocks.4.0.bn1.weight\", \"blocks.4.0.bn1.bias\", \"blocks.4.0.bn1.running_mean\", \"blocks.4.0.bn1.running_var\", \"blocks.4.0.bn1.num_batches_tracked\", \"blocks.4.0.conv_dw.weight\", \"blocks.4.0.bn2.weight\", \"blocks.4.0.bn2.bias\", \"blocks.4.0.bn2.running_mean\", \"blocks.4.0.bn2.running_var\", \"blocks.4.0.bn2.num_batches_tracked\", \"blocks.4.0.se.conv_reduce.weight\", \"blocks.4.0.se.conv_reduce.bias\", \"blocks.4.0.se.conv_expand.weight\", \"blocks.4.0.se.conv_expand.bias\", \"blocks.4.0.conv_pwl.weight\", \"blocks.4.0.bn3.weight\", \"blocks.4.0.bn3.bias\", \"blocks.4.0.bn3.running_mean\", \"blocks.4.0.bn3.running_var\", \"blocks.4.0.bn3.num_batches_tracked\", \"blocks.4.1.conv_pw.weight\", \"blocks.4.1.bn1.weight\", \"blocks.4.1.bn1.bias\", \"blocks.4.1.bn1.running_mean\", \"blocks.4.1.bn1.running_var\", \"blocks.4.1.bn1.num_batches_tracked\", \"blocks.4.1.conv_dw.weight\", \"blocks.4.1.bn2.weight\", \"blocks.4.1.bn2.bias\", \"blocks.4.1.bn2.running_mean\", \"blocks.4.1.bn2.running_var\", \"blocks.4.1.bn2.num_batches_tracked\", \"blocks.4.1.se.conv_reduce.weight\", \"blocks.4.1.se.conv_reduce.bias\", \"blocks.4.1.se.conv_expand.weight\", \"blocks.4.1.se.conv_expand.bias\", \"blocks.4.1.conv_pwl.weight\", \"blocks.4.1.bn3.weight\", \"blocks.4.1.bn3.bias\", \"blocks.4.1.bn3.running_mean\", \"blocks.4.1.bn3.running_var\", \"blocks.4.1.bn3.num_batches_tracked\", \"blocks.4.2.conv_pw.weight\", \"blocks.4.2.bn1.weight\", \"blocks.4.2.bn1.bias\", \"blocks.4.2.bn1.running_mean\", \"blocks.4.2.bn1.running_var\", \"blocks.4.2.bn1.num_batches_tracked\", \"blocks.4.2.conv_dw.weight\", \"blocks.4.2.bn2.weight\", \"blocks.4.2.bn2.bias\", \"blocks.4.2.bn2.running_mean\", \"blocks.4.2.bn2.running_var\", \"blocks.4.2.bn2.num_batches_tracked\", \"blocks.4.2.se.conv_reduce.weight\", \"blocks.4.2.se.conv_reduce.bias\", \"blocks.4.2.se.conv_expand.weight\", \"blocks.4.2.se.conv_expand.bias\", \"blocks.4.2.conv_pwl.weight\", \"blocks.4.2.bn3.weight\", \"blocks.4.2.bn3.bias\", \"blocks.4.2.bn3.running_mean\", \"blocks.4.2.bn3.running_var\", \"blocks.4.2.bn3.num_batches_tracked\", \"blocks.4.3.conv_pw.weight\", \"blocks.4.3.bn1.weight\", \"blocks.4.3.bn1.bias\", \"blocks.4.3.bn1.running_mean\", \"blocks.4.3.bn1.running_var\", \"blocks.4.3.bn1.num_batches_tracked\", \"blocks.4.3.conv_dw.weight\", \"blocks.4.3.bn2.weight\", \"blocks.4.3.bn2.bias\", \"blocks.4.3.bn2.running_mean\", \"blocks.4.3.bn2.running_var\", \"blocks.4.3.bn2.num_batches_tracked\", \"blocks.4.3.se.conv_reduce.weight\", \"blocks.4.3.se.conv_reduce.bias\", \"blocks.4.3.se.conv_expand.weight\", \"blocks.4.3.se.conv_expand.bias\", \"blocks.4.3.conv_pwl.weight\", \"blocks.4.3.bn3.weight\", \"blocks.4.3.bn3.bias\", \"blocks.4.3.bn3.running_mean\", \"blocks.4.3.bn3.running_var\", \"blocks.4.3.bn3.num_batches_tracked\", \"blocks.5.0.conv_pw.weight\", \"blocks.5.0.bn1.weight\", \"blocks.5.0.bn1.bias\", \"blocks.5.0.bn1.running_mean\", \"blocks.5.0.bn1.running_var\", \"blocks.5.0.bn1.num_batches_tracked\", \"blocks.5.0.conv_dw.weight\", \"blocks.5.0.bn2.weight\", \"blocks.5.0.bn2.bias\", \"blocks.5.0.bn2.running_mean\", \"blocks.5.0.bn2.running_var\", \"blocks.5.0.bn2.num_batches_tracked\", \"blocks.5.0.se.conv_reduce.weight\", \"blocks.5.0.se.conv_reduce.bias\", \"blocks.5.0.se.conv_expand.weight\", \"blocks.5.0.se.conv_expand.bias\", \"blocks.5.0.conv_pwl.weight\", \"blocks.5.0.bn3.weight\", \"blocks.5.0.bn3.bias\", \"blocks.5.0.bn3.running_mean\", \"blocks.5.0.bn3.running_var\", \"blocks.5.0.bn3.num_batches_tracked\", \"blocks.5.1.conv_pw.weight\", \"blocks.5.1.bn1.weight\", \"blocks.5.1.bn1.bias\", \"blocks.5.1.bn1.running_mean\", \"blocks.5.1.bn1.running_var\", \"blocks.5.1.bn1.num_batches_tracked\", \"blocks.5.1.conv_dw.weight\", \"blocks.5.1.bn2.weight\", \"blocks.5.1.bn2.bias\", \"blocks.5.1.bn2.running_mean\", \"blocks.5.1.bn2.running_var\", \"blocks.5.1.bn2.num_batches_tracked\", \"blocks.5.1.se.conv_reduce.weight\", \"blocks.5.1.se.conv_reduce.bias\", \"blocks.5.1.se.conv_expand.weight\", \"blocks.5.1.se.conv_expand.bias\", \"blocks.5.1.conv_pwl.weight\", \"blocks.5.1.bn3.weight\", \"blocks.5.1.bn3.bias\", \"blocks.5.1.bn3.running_mean\", \"blocks.5.1.bn3.running_var\", \"blocks.5.1.bn3.num_batches_tracked\", \"blocks.5.2.conv_pw.weight\", \"blocks.5.2.bn1.weight\", \"blocks.5.2.bn1.bias\", \"blocks.5.2.bn1.running_mean\", \"blocks.5.2.bn1.running_var\", \"blocks.5.2.bn1.num_batches_tracked\", \"blocks.5.2.conv_dw.weight\", \"blocks.5.2.bn2.weight\", \"blocks.5.2.bn2.bias\", \"blocks.5.2.bn2.running_mean\", \"blocks.5.2.bn2.running_var\", \"blocks.5.2.bn2.num_batches_tracked\", \"blocks.5.2.se.conv_reduce.weight\", \"blocks.5.2.se.conv_reduce.bias\", \"blocks.5.2.se.conv_expand.weight\", \"blocks.5.2.se.conv_expand.bias\", \"blocks.5.2.conv_pwl.weight\", \"blocks.5.2.bn3.weight\", \"blocks.5.2.bn3.bias\", \"blocks.5.2.bn3.running_mean\", \"blocks.5.2.bn3.running_var\", \"blocks.5.2.bn3.num_batches_tracked\", \"blocks.5.3.conv_pw.weight\", \"blocks.5.3.bn1.weight\", \"blocks.5.3.bn1.bias\", \"blocks.5.3.bn1.running_mean\", \"blocks.5.3.bn1.running_var\", \"blocks.5.3.bn1.num_batches_tracked\", \"blocks.5.3.conv_dw.weight\", \"blocks.5.3.bn2.weight\", \"blocks.5.3.bn2.bias\", \"blocks.5.3.bn2.running_mean\", \"blocks.5.3.bn2.running_var\", \"blocks.5.3.bn2.num_batches_tracked\", \"blocks.5.3.se.conv_reduce.weight\", \"blocks.5.3.se.conv_reduce.bias\", \"blocks.5.3.se.conv_expand.weight\", \"blocks.5.3.se.conv_expand.bias\", \"blocks.5.3.conv_pwl.weight\", \"blocks.5.3.bn3.weight\", \"blocks.5.3.bn3.bias\", \"blocks.5.3.bn3.running_mean\", \"blocks.5.3.bn3.running_var\", \"blocks.5.3.bn3.num_batches_tracked\", \"blocks.5.4.conv_pw.weight\", \"blocks.5.4.bn1.weight\", \"blocks.5.4.bn1.bias\", \"blocks.5.4.bn1.running_mean\", \"blocks.5.4.bn1.running_var\", \"blocks.5.4.bn1.num_batches_tracked\", \"blocks.5.4.conv_dw.weight\", \"blocks.5.4.bn2.weight\", \"blocks.5.4.bn2.bias\", \"blocks.5.4.bn2.running_mean\", \"blocks.5.4.bn2.running_var\", \"blocks.5.4.bn2.num_batches_tracked\", \"blocks.5.4.se.conv_reduce.weight\", \"blocks.5.4.se.conv_reduce.bias\", \"blocks.5.4.se.conv_expand.weight\", \"blocks.5.4.se.conv_expand.bias\", \"blocks.5.4.conv_pwl.weight\", \"blocks.5.4.bn3.weight\", \"blocks.5.4.bn3.bias\", \"blocks.5.4.bn3.running_mean\", \"blocks.5.4.bn3.running_var\", \"blocks.5.4.bn3.num_batches_tracked\", \"blocks.6.0.conv_pw.weight\", \"blocks.6.0.bn1.weight\", \"blocks.6.0.bn1.bias\", \"blocks.6.0.bn1.running_mean\", \"blocks.6.0.bn1.running_var\", \"blocks.6.0.bn1.num_batches_tracked\", \"blocks.6.0.conv_dw.weight\", \"blocks.6.0.bn2.weight\", \"blocks.6.0.bn2.bias\", \"blocks.6.0.bn2.running_mean\", \"blocks.6.0.bn2.running_var\", \"blocks.6.0.bn2.num_batches_tracked\", \"blocks.6.0.se.conv_reduce.weight\", \"blocks.6.0.se.conv_reduce.bias\", \"blocks.6.0.se.conv_expand.weight\", \"blocks.6.0.se.conv_expand.bias\", \"blocks.6.0.conv_pwl.weight\", \"blocks.6.0.bn3.weight\", \"blocks.6.0.bn3.bias\", \"blocks.6.0.bn3.running_mean\", \"blocks.6.0.bn3.running_var\", \"blocks.6.0.bn3.num_batches_tracked\", \"blocks.6.1.conv_pw.weight\", \"blocks.6.1.bn1.weight\", \"blocks.6.1.bn1.bias\", \"blocks.6.1.bn1.running_mean\", \"blocks.6.1.bn1.running_var\", \"blocks.6.1.bn1.num_batches_tracked\", \"blocks.6.1.conv_dw.weight\", \"blocks.6.1.bn2.weight\", \"blocks.6.1.bn2.bias\", \"blocks.6.1.bn2.running_mean\", \"blocks.6.1.bn2.running_var\", \"blocks.6.1.bn2.num_batches_tracked\", \"blocks.6.1.se.conv_reduce.weight\", \"blocks.6.1.se.conv_reduce.bias\", \"blocks.6.1.se.conv_expand.weight\", \"blocks.6.1.se.conv_expand.bias\", \"blocks.6.1.conv_pwl.weight\", \"blocks.6.1.bn3.weight\", \"blocks.6.1.bn3.bias\", \"blocks.6.1.bn3.running_mean\", \"blocks.6.1.bn3.running_var\", \"blocks.6.1.bn3.num_batches_tracked\", \"conv_head.weight\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"classifier.weight\", \"classifier.bias\". \n\tsize mismatch for bn1.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for bn1.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64])."
     ]
    }
   ],
   "source": [
    "model = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) \n",
    "\n",
    "PATH = f\"./results/{name}/best.ckpt\"\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer= ['nan', 'text', 'mark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val loop\n",
    "with torch.no_grad():\n",
    "    print(\"Calculating validation results...\")\n",
    "    model.eval()\n",
    "    val_loss_items = []\n",
    "    val_acc_items = []\n",
    "    for val_batch in test_loader:\n",
    "        inputs = val_batch\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        \n",
    "        print(answer[int(preds)])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
