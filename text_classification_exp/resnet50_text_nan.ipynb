{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import timm\n",
    "import yaml\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, StepLR\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from easydict import EasyDict\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "num_epochs = 50\n",
    "accumulation_steps = 2\n",
    "batch_size = 64\n",
    "train_log_interval = 100\n",
    "\n",
    "LEARNING_RATE = 0.0001 \n",
    "lr_decay_step = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring csv & Delete noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'OpenData_PotOpenTabletIdntfc20220412.xls'\n",
    "df = pd.read_excel(filename, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete 구강정 데이터\n",
    "index_delete1 = df[df['품목일련번호']==200605327].index\n",
    "index_delete2 = df[df['품목일련번호']==200605328].index\n",
    "index_delete3 = df[df['품목일련번호']==200605329].index\n",
    "index_delete4 = df[df['품목일련번호']==200605330].index\n",
    "index_delete5 = df[df['품목일련번호']==200605331].index\n",
    "index_delete6 = df[df['품목일련번호']==200606263].index\n",
    "\n",
    "## delete 반원형 데이터\n",
    "index_delete7 = df[df['품목일련번호']==197800388].index\n",
    "index_delete8 = df[df['품목일련번호']==199906868].index\n",
    "index_delete9 = df[df['품목일련번호']==197900378].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index_delete1)\n",
    "df = df.drop(index_delete2)\n",
    "df = df.drop(index_delete3)\n",
    "df = df.drop(index_delete4)\n",
    "df = df.drop(index_delete5)\n",
    "df = df.drop(index_delete6)\n",
    "df = df.drop(index_delete7)\n",
    "df = df.drop(index_delete8)\n",
    "df = df.drop(index_delete9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_text_nan = []\n",
    "for front, back in df.iloc[:, [6, 7]].values:\n",
    "    # nan: 0, text: 1\n",
    "    if type(front) is float and type(back) is float:\n",
    "        is_text_nan.append(0)\n",
    "    else:\n",
    "        is_text_nan.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(29, 'is_text_nan', is_text_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(is_text_nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index()\n",
    "        self.image_id = self.df['품목일련번호']\n",
    "        self.labels = self.df['is_text_nan']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_id[idx]\n",
    "        label = self.labels[idx]\n",
    "        image_path = f'/opt/ml/data_handling/data/{image_id}.jpg'\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = df['품목일련번호']\n",
    "label = df['is_text_nan']\n",
    "\n",
    "# https://teddylee777.github.io/scikit-learn/train-test-split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(image_num, label, test_size=0.2, stratify=label, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://mizykk.tistory.com/131\n",
    "\n",
    "train_zip = zip(x_train, y_train)\n",
    "train_df = pd.DataFrame(train_zip)\n",
    "train_df.columns = ['품목일련번호','is_text_nan']\n",
    "\n",
    "val_zip = zip(x_valid, y_valid)\n",
    "val_df = pd.DataFrame(val_zip)\n",
    "val_df.columns = ['품목일련번호','is_text_nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>품목일련번호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_text_nan</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             품목일련번호\n",
       "is_text_nan        \n",
       "0               147\n",
       "1             19343"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('is_text_nan').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "품목일련번호    19490\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('is_text_nan').count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>품목일련번호</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_text_nan</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             품목일련번호\n",
       "is_text_nan        \n",
       "0                37\n",
       "1              4836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.groupby('is_text_nan').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "품목일련번호    4873\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.groupby('is_text_nan').count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "val_dataset = CustomDataset(val_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.7077, 0.7077, 0.7077,  ..., 0.7077, 0.7077, 0.7077],\n",
       "          [0.7077, 0.7077, 0.7077,  ..., 0.7077, 0.7077, 0.7077],\n",
       "          [0.7077, 0.7077, 0.7077,  ..., 0.7077, 0.7077, 0.7077],\n",
       "          ...,\n",
       "          [0.7077, 0.7077, 0.7077,  ..., 0.7077, 0.7077, 0.6906],\n",
       "          [0.7077, 0.7077, 0.7077,  ..., 0.7077, 0.7077, 0.6906],\n",
       "          [0.6734, 0.6906, 0.6906,  ..., 0.6734, 0.6734, 0.6734]],\n",
       " \n",
       "         [[1.3256, 1.3256, 1.3256,  ..., 1.3256, 1.3256, 1.3256],\n",
       "          [1.3256, 1.3256, 1.3256,  ..., 1.3256, 1.3256, 1.3256],\n",
       "          [1.3256, 1.3256, 1.3256,  ..., 1.3256, 1.3256, 1.3256],\n",
       "          ...,\n",
       "          [1.3256, 1.3256, 1.3256,  ..., 1.3256, 1.3256, 1.3081],\n",
       "          [1.3256, 1.3256, 1.3256,  ..., 1.3256, 1.3256, 1.3081],\n",
       "          [1.2906, 1.3081, 1.3081,  ..., 1.2906, 1.2906, 1.2906]],\n",
       " \n",
       "         [[2.2914, 2.2914, 2.2914,  ..., 2.2914, 2.2914, 2.2914],\n",
       "          [2.2914, 2.2914, 2.2914,  ..., 2.2914, 2.2914, 2.2914],\n",
       "          [2.2914, 2.2914, 2.2914,  ..., 2.2914, 2.2914, 2.2914],\n",
       "          ...,\n",
       "          [2.2914, 2.2914, 2.2914,  ..., 2.2914, 2.2914, 2.2740],\n",
       "          [2.2914, 2.2914, 2.2914,  ..., 2.2914, 2.2914, 2.2740],\n",
       "          [2.2566, 2.2740, 2.2740,  ..., 2.2566, 2.2566, 2.2566]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(train_dataset))\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          ...,\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529],\n",
       "          [1.1529, 1.1529, 1.1529,  ..., 1.1529, 1.1529, 1.1529]],\n",
       " \n",
       "         [[1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          ...,\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707],\n",
       "          [1.5707, 1.5707, 1.5707,  ..., 1.5707, 1.5707, 1.5707]],\n",
       " \n",
       "         [[2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          ...,\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171],\n",
       "          [2.1171, 2.1171, 2.1171,  ..., 2.1171, 2.1171, 2.1171]]]),\n",
       " 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(val_dataset))\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'resnet50'\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
    "scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseoulsky_field\u001b[0m (\u001b[33mmedic\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/ml/final-project-level3-cv-16/wandb/run-20220526_012240-33imr5re</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/medic/final-project/runs/33imr5re\" target=\"_blank\">KM_resnet50_text_nan</a></strong> to <a href=\"https://wandb.ai/medic/final-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68777e6882e14f9f81f90cb372273c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/50](100/305) || training loss 0.05971 || training accuracy 98.38% || lr [0.0001]\n",
      "Epoch[0/50](200/305) || training loss 0.01239 || training accuracy 99.58% || lr [0.0001]\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [0.89189189 0.99979322]\n",
      "[Val] acc : 99.90%, loss: 0.0052 || best acc : 99.90%, best loss: 0.0052\n",
      "nan: 0.8918918918918919\n",
      "text: 0.999793217535153\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213be63322a24fa09c4f5a5c52978211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/50](100/305) || training loss 0.008419 || training accuracy 99.73% || lr [0.0001]\n",
      "Epoch[1/50](200/305) || training loss 0.003749 || training accuracy 99.92% || lr [0.0001]\n",
      "Epoch[1/50](300/305) || training loss 0.004406 || training accuracy 99.86% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.7027027  0.99979322]\n",
      "[Val] acc : 99.75%, loss: 0.0048 || best acc : 99.90%, best loss: 0.0048\n",
      "nan: 0.7027027027027027\n",
      "text: 0.999793217535153\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113b6f1dba45406cb9880c42bc26ff16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/50](100/305) || training loss 0.003737 || training accuracy 99.88% || lr [0.0001]\n",
      "Epoch[2/50](200/305) || training loss 0.007684 || training accuracy 99.66% || lr [0.0001]\n",
      "Epoch[2/50](300/305) || training loss 0.005171 || training accuracy 99.83% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.78378378 0.99979322]\n",
      "[Val] acc : 99.82%, loss: 0.01 || best acc : 99.90%, best loss: 0.0048\n",
      "nan: 0.7837837837837838\n",
      "text: 0.999793217535153\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd2d6289c75451d98fc734f9d88ec57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/50](100/305) || training loss 0.004662 || training accuracy 99.91% || lr [0.0001]\n",
      "Epoch[3/50](200/305) || training loss 0.003932 || training accuracy 99.89% || lr [0.0001]\n",
      "Epoch[3/50](300/305) || training loss 0.001807 || training accuracy 99.97% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.89189189 0.99937965]\n",
      "[Val] acc : 99.86%, loss: 0.0042 || best acc : 99.90%, best loss: 0.0042\n",
      "nan: 0.8918918918918919\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f56227c48aa4313aff2451e96493ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/50](100/305) || training loss 0.000796 || training accuracy 99.98% || lr [0.0001]\n",
      "Epoch[4/50](200/305) || training loss 0.001684 || training accuracy 99.98% || lr [0.0001]\n",
      "Epoch[4/50](300/305) || training loss 0.002485 || training accuracy 99.94% || lr [0.0001]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99937965]\n",
      "[Val] acc : 99.90%, loss: 0.0035 || best acc : 99.90%, best loss: 0.0035\n",
      "nan: 0.9459459459459459\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0020a2ad61774313b63157115e7662a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/50](100/305) || training loss 0.001672 || training accuracy 99.92% || lr [5e-05]\n",
      "Epoch[5/50](200/305) || training loss 0.001483 || training accuracy 99.94% || lr [5e-05]\n",
      "Epoch[5/50](300/305) || training loss 0.001495 || training accuracy 99.95% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "accuracy by label: [1.         0.99937965]\n",
      "[Val] acc : 99.94%, loss: 0.0022 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 1.0\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c5878c9ad4471b8b6f7554faee01dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/50](100/305) || training loss 0.0003451 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[6/50](200/305) || training loss 0.0004305 || training accuracy 99.98% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [1.         0.99875931]\n",
      "[Val] acc : 99.88%, loss: 0.0033 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 1.0\n",
      "text: 0.9987593052109182\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacb7a0a9b6340c282239e9b13f12577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/50](100/305) || training loss 0.0002285 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/50](200/305) || training loss 6.143e-05 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/50](300/305) || training loss 0.0001345 || training accuracy 100.00% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [1.         0.99896609]\n",
      "[Val] acc : 99.90%, loss: 0.0034 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 1.0\n",
      "text: 0.9989660876757651\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfe873d553e4c939fda3a4a29f1dc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/50](100/305) || training loss 4.635e-05 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/50](200/305) || training loss 4.365e-05 || training accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/50](300/305) || training loss 0.0002078 || training accuracy 100.00% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.97297297 0.99937965]\n",
      "[Val] acc : 99.92%, loss: 0.0032 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.972972972972973\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341f124fb86d4abc914b479efc7f4249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/50](100/305) || training loss 0.002081 || training accuracy 99.94% || lr [5e-05]\n",
      "Epoch[9/50](200/305) || training loss 0.0008714 || training accuracy 99.95% || lr [5e-05]\n",
      "Epoch[9/50](300/305) || training loss 0.0001098 || training accuracy 100.00% || lr [5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99917287]\n",
      "[Val] acc : 99.88%, loss: 0.0051 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.9459459459459459\n",
      "text: 0.9991728701406121\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5f6e4ff4cb47f188892232fd7c6c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/50](100/305) || training loss 0.0005904 || training accuracy 99.98% || lr [2.5e-05]\n",
      "Epoch[10/50](200/305) || training loss 0.0001117 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[10/50](300/305) || training loss 4.23e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.91891892 0.99958644]\n",
      "[Val] acc : 99.90%, loss: 0.0031 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.918918918918919\n",
      "text: 0.9995864350703061\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c02c6dd9dfb4a318c78301dfef41205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11/50](100/305) || training loss 0.0001067 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[11/50](200/305) || training loss 0.0001154 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[11/50](300/305) || training loss 7.464e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99937965]\n",
      "[Val] acc : 99.90%, loss: 0.0032 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.9459459459459459\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f921b4d37f24877a864238cb68fc9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/50](100/305) || training loss 6.565e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[12/50](200/305) || training loss 3.008e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[12/50](300/305) || training loss 3.497e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99937965]\n",
      "[Val] acc : 99.90%, loss: 0.0036 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.9459459459459459\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9dbcca099f4204b117e1034f6846f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/50](100/305) || training loss 2.902e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[13/50](200/305) || training loss 2.29e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[13/50](300/305) || training loss 4.968e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99958644]\n",
      "[Val] acc : 99.92%, loss: 0.0037 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.9459459459459459\n",
      "text: 0.9995864350703061\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac48ec8892e24a65af4d01164d979ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14/50](100/305) || training loss 4.913e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[14/50](200/305) || training loss 2.232e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "Epoch[14/50](300/305) || training loss 3.668e-05 || training accuracy 100.00% || lr [2.5e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99937965]\n",
      "[Val] acc : 99.90%, loss: 0.0037 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.9459459459459459\n",
      "text: 0.999379652605459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a1445f2cb44ecaada5bc1935984aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/50](100/305) || training loss 3.182e-05 || training accuracy 100.00% || lr [1.25e-05]\n",
      "Epoch[15/50](200/305) || training loss 2.409e-05 || training accuracy 100.00% || lr [1.25e-05]\n",
      "Epoch[15/50](300/305) || training loss 1.919e-05 || training accuracy 100.00% || lr [1.25e-05]\n",
      "\n",
      "Calculating validation results...\n",
      "accuracy by label: [0.94594595 0.99896609]\n",
      "[Val] acc : 99.86%, loss: 0.0047 || best acc : 99.94%, best loss: 0.0022\n",
      "nan: 0.9459459459459459\n",
      "text: 0.9989660876757651\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980fccb9fee643c8918e30118dd8153a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16/50](100/305) || training loss 1.814e-05 || training accuracy 100.00% || lr [1.25e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"final-project\", entity=\"medic\", name=f\"KM_{model_name}_text_nan\")\n",
    "\n",
    "name = f'{model_name}_type_and_shape'\n",
    "os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n",
    "\n",
    "counter = 0\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "    for idx, train_batch in tqdm(enumerate(train_loader)):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # -- Gradient Accumulation\n",
    "        if (idx+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % train_log_interval == 0:\n",
    "            train_loss = loss_value / train_log_interval\n",
    "            train_acc = matches / batch_size / train_log_interval\n",
    "            current_lr = scheduler.get_last_lr()\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "            \n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        label_accuracy, total_label = [0]*num_classes, [0]*num_classes\n",
    "        for val_batch in val_loader:\n",
    "            inputs, labels = val_batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "            \n",
    "            ## label별 accuracy\n",
    "            for i in range(len(labels)):\n",
    "                total_label[int(labels[i])] += 1\n",
    "                if labels[i] == preds[i]:\n",
    "                    label_accuracy[int(labels[i])] += 1\n",
    "            \n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_df)\n",
    "        \n",
    "        # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        if val_acc > best_val_acc:\n",
    "            print(\"New best model for val accuracy! saving the model..\")\n",
    "            torch.save(model.state_dict(), f\"results/{name}/best.ckpt\")\n",
    "            best_val_acc = val_acc\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n",
    "        if counter > patience:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "        \n",
    "        ## 파이썬 배열 나눗셈 https://bearwoong.tistory.com/60\n",
    "        accuracy_by_label = np.array(label_accuracy)/np.array(total_label)\n",
    "        print(f\"accuracy by label: {accuracy_by_label}\")\n",
    "        \n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )\n",
    "        \n",
    "        print(\n",
    "            f\"nan: {accuracy_by_label[0]}\\n\"\n",
    "            f\"text: {accuracy_by_label[1]}\\n\"\n",
    "        )\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"valid_loss\": val_loss,\n",
    "        \"valid_accuracy\": val_acc,\n",
    "        \"best_loss\": best_val_loss,\n",
    "        \"best_accuracy\": best_val_acc,\n",
    "        \"nan\": accuracy_by_label[0],\n",
    "        \"text\": accuracy_by_label[1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index()\n",
    "        self.image_id = self.df['품목일련번호']\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_id = self.image_id[idx]\n",
    "        image_path = f'/opt/ml/final-project-level3-cv-16/test_data/{image_id}'\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = './test_data'\n",
    "test_list = os.listdir(image_dir)\n",
    "test_list = sorted(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_list)\n",
    "test_df.columns = ['품목일련번호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "test_dataset = CustomTestDataset(test_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2043, 1.1700, 1.1358,  ..., 0.2967, 0.2282, 0.3138],\n",
       "         [1.2214, 1.1015, 1.1872,  ..., 0.1768, 0.1597, 0.2453],\n",
       "         [1.1358, 1.1187, 1.1358,  ..., 0.2282, 0.2796, 0.2796],\n",
       "         ...,\n",
       "         [0.6392, 0.6221, 0.5878,  ..., 0.6734, 0.5707, 0.6221],\n",
       "         [0.4508, 0.4508, 0.5022,  ..., 0.7077, 0.7933, 0.7591],\n",
       "         [0.5022, 0.5364, 0.5022,  ..., 0.6906, 0.7933, 0.7933]],\n",
       "\n",
       "        [[1.4307, 1.3782, 1.3431,  ..., 0.3452, 0.2402, 0.3803],\n",
       "         [1.4482, 1.3256, 1.4132,  ..., 0.2052, 0.1877, 0.2927],\n",
       "         [1.3431, 1.3081, 1.3431,  ..., 0.2927, 0.3277, 0.3277],\n",
       "         ...,\n",
       "         [0.7129, 0.6779, 0.6429,  ..., 0.7654, 0.6429, 0.6954],\n",
       "         [0.4853, 0.4853, 0.5378,  ..., 0.8179, 0.9230, 0.8880],\n",
       "         [0.5553, 0.5728, 0.5203,  ..., 0.8004, 0.9230, 0.9230]],\n",
       "\n",
       "        [[1.5245, 1.5071, 1.4548,  ..., 0.4439, 0.3219, 0.4439],\n",
       "         [1.5768, 1.4374, 1.5420,  ..., 0.3045, 0.2696, 0.3742],\n",
       "         [1.4722, 1.4374, 1.4722,  ..., 0.3742, 0.4091, 0.4091],\n",
       "         ...,\n",
       "         [0.8797, 0.8448, 0.7925,  ..., 0.8797, 0.7751, 0.8099],\n",
       "         [0.6182, 0.6356, 0.6879,  ..., 0.9668, 1.0714, 1.0365],\n",
       "         [0.7054, 0.7228, 0.6879,  ..., 0.9494, 1.0539, 1.0714]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = next(iter(test_dataset))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) \n",
    "\n",
    "PATH = f\"./results/{name}/best.ckpt\"\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer= ['nan', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating validation results...\n",
      "text\n",
      "text\n",
      "text\n",
      "nan\n",
      "text\n",
      "nan\n",
      "text\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "text\n",
      "nan\n",
      "nan\n",
      "text\n",
      "nan\n",
      "text\n",
      "nan\n",
      "text\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "text\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "text\n",
      "text\n",
      "text\n",
      "text\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "# val loop\n",
    "with torch.no_grad():\n",
    "    print(\"Calculating validation results...\")\n",
    "    model.eval()\n",
    "    val_loss_items = []\n",
    "    val_acc_items = []\n",
    "    for val_batch in test_loader:\n",
    "        inputs = val_batch\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        \n",
    "        print(answer[int(preds)])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
